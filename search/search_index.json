{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"80% of the product development lifecycle will make use of generative AI-derived code by 2025 \u2014Gartner Take a moment to consider just how much code that 80% represents \u2014 and how quickly generative AI has moved to the forefront of nearly every industry. What began to simmer in the early 2020s, as excitement within academic and technology communities around transformers, has today exploded into a firestorm of interest and investment across nearly every industry, institution, and government. For the first time at scale, everyday consumers have access to artificial intelligence (AI) on their phones and through their web browsers. Likewise, enterprise and business leaders no longer view AI as a topic of interest, but as a critical imperative to success in the future economy. Foundation models \u2014 a term coined by Stanford University \u2014 are built using a specific kind of neural network architecture, called a transformer . The transformer architecture helps foundation models understand unlabeled data and turn an input into an output. The most consequential manifestation of this technology so far is what we know today as \" generative AI .\" So what is generative AI ? The vast topic refers to a subset of AI techniques and methodologies that are designed to generate new content \u2014 in other words, AI applied towards the creation of novel content in the form of images, text, voice, and even programming code. This sharply differs from the goals of more \"traditional\" AI models of the past, which have primarily been focused on the analysis and classification (labeling) of information. Historically, these early pioneering techniques of AI models have progressed from simple probabilistic models into increasingly sophisticated systems, building upon concepts like neural networks and deep learning techniques. Today, technologies like generative AI showcase not only the ability to perform analysis, but also tremendous capacity for creation. Even the creation of application code and automation tasks. The advent of foundation models and generative AI, given their remarkable performance and extensibility to a wide range of tasks, has brought about an inflection point in AI. Recognizing the significance of the moment, IBM enterprise clients are actively evaluating and seeking to incorporate foundation models into critical business workflows and applications \u2014 anything and everything which involves generation, summarization, classification, and many other use cases. IBM-trained watsonx.ai CodeLLM is a Large Language Model (LLM) for programming languages and code, one of the many foundation models available to IBM watsonx.ai \u2014 and then further refined and calibrated for use with specific programming languages like COBOL, Ansible, and others. IBM watsonx Code Assistant is the flagship product for generative AI services, with a variety of options ( for Red Hat Ansible Lightspeed , for Z ) that are tailored to specific client use cases and business goals. The notion of automating the generation of Ansible Playbook code with AI stems from the challenges and bottlenecks often faced by developers tasked with traditional, manual creation of Playbooks IBM watsonx Code Assistant (WCA) is powered by IBM Granite foundation models, based on decoder-only transformer architecture. Granite language models are trained on trusted enterprise data spanning internet, academic, and code \u2014 especially open-source code repositories like GitHub and Ansible Galaxy. IBM Granite is a 20-billion parameter model for code that was trained on 1.6 trillion code tokens. Within these models, IBM performs a comprehensive sweep to filter out sensitive, toxic, and copyright-protected code. Those models are then pre-trained on datasets for automation (Ansible content) and application modernization. The result are highly specialized models that can immediately go to work in service of IBM enterprise client's highest priority use cases. WHAT ARE PLAYBOOKS? Ansible Playbooks instruct Ansible\u2019s automation engine on how to execute tasks in a step-by-step manner. Playbooks defines roles, tasks, handlers, and other configurations; in turn, these attributes allow developers and users to codify complex orchestration scenarios. Conceptually, think of a Playbook as a recipe book for system administration: each recipe (or Playbook) spells out the steps required to achieve a particular system state or to complete a given operation. One of the standout features of Ansible Playbooks is that they are idempotent : executing Playbooks them multiple times on the same system won't create additional \"side effects\" (unintended operations or creation of unwanted artifacts) after the first successful run. This ensures consistency and reliability across deployments of the Red Hat Ansible Automation Platform ( AAP ). 30% faster time to value observed in IT automation by adopting IBM watsonx Code Assistant with Red Hat Ansible Lightspeed Enterprise clients that are delivering an IT automation practice within their organization can be more efficient, can trust in the accuracy of their AI-generated content, and can upskill their teams faster. Regarding security\u2014 of upmost concern to enterprise organizations \u2014the natural language prompts sent to WCA and the code recommendations returned by WCA are both encrypted (in-transit and at-rest.) The generative AI recommendations are also ephemeral: IBM does not store or retain prompts, recommendations, or code. The prompt is discarded as soon as a recommendation is ready to send back to a client; likewise, that recommendation is never retained by IBM. When there is client data submitted by the user to WCA, such as when a client is looking to perform model customization based on their own datasets (something this training will explore in detail), that data is stored directly within a client-owned Cloud Object Storage instance. The data remains accessible only to the client \u2014 it is impervious to IBM, Red Hat, or any other user besides the client who owns it. There are three core components to the hands-on training environment: Visual Studio Code (VS Code) running on your local machine, connected via VS Code Extensions to... Ansible Automation Platform (AAP) running on the Red Hat cloud, licensed for use with Red Hat Ansible Lightspeed and integrated with... IBM watsonx Code Assistant (WCA) running on IBM Cloud, providing generative AI and model customization Developers and programmers must craft precise, error-free Playbooks which are potentially automating jobs across vast collections of assets or hardware. One of the benefits of automation is being able to perform such tasks at-scale; conversely, this also poses one of the greatest risks of automation \u2014 that if things fail, they can fail rapidly and across vast swathes of IT estate. It should come as no surprise, then, that authoring Playbooks often demands technical expertise and a deep understanding of the targeted systems and services which Ansible is to automate. Generative AI has recently demonstrated proficiency in creating syntactically correct and contextually relevant application code in a variety of programming languages. For example, if trained on a large dataset of Ansible Playbooks, generative AI models can be fine-tuned to understand the nuances of Playbook syntax and structure. An enterprise organization with dozens or hundreds of Playbooks within their IT estate today would have a rich corpus of training data on-hand that could be used to fine-tune AI models that are tailored to the automation needs and programming style or standards of that particular company. As you will see throughout the hands-on training material, generative AI models provide a natural language prompt to users which in turn is understood and translated by the AI models into the necessary Ansible Task code. For example, a user might describe a desired system state in plain language (\"I want a Playbook to install and start the Apache web server\") and the model will generate the appropriate Ansible Tasks for a Playbook. All of this achieved without physically writing code or requiring much programming expertise. Not only does this speed up the automation process by cutting the time needed to author Playbooks, but it also democratizes access to automation in general. Even those within a company with limited Ansible or programming expertise will be able to produce effective Playbooks. There are plenty of caveats of course, and thorough validation and testing of AI-generated code will be needed before being put into production. However, the productivity gains and broadening of skillsets within an organization can be tremendous. And as a whole, generative AI brings the original goals of Red Hat Ansible Automation Platform (the democratization of automation for everything) that much closer to a reality. The material covered in this hands-on training is intended to prepare IBM clients with the skills necessary to create Ansible Playbook tasks using the generative AI capabilities of WCA The curriculum will leverage WCA's generative AI code recommendations for automating cloud-based and infrastructure-based automation tasks. In-depth explanations accompanying Ansible Playbook templates will also explain: How WCA uses natural language prompts , as well as Ansible Playbook contents, to generate contextually-aware Task code recommendations Post-processing capabilities that refine the generative AI suggestions into syntactically correct code (adherent to best practices) How WCA provides content source matching attribution and \"explainability\" for all AI-generated content Leveraging WCA's model tuning capabilities to tailor content and code recommendations to an organization's standards, best practices, and programming styles Next steps In the following section, you will prepare your hands-on lab environment with the necessary services and configurations.","title":"Introduction"},{"location":"#_1","text":"","title":""},{"location":"#80-of-the-product-development-lifecycle-will-make-use-of-generative-ai-derived-code-by-2025-gartner","text":"Take a moment to consider just how much code that 80% represents \u2014 and how quickly generative AI has moved to the forefront of nearly every industry. What began to simmer in the early 2020s, as excitement within academic and technology communities around transformers, has today exploded into a firestorm of interest and investment across nearly every industry, institution, and government. For the first time at scale, everyday consumers have access to artificial intelligence (AI) on their phones and through their web browsers. Likewise, enterprise and business leaders no longer view AI as a topic of interest, but as a critical imperative to success in the future economy. Foundation models \u2014 a term coined by Stanford University \u2014 are built using a specific kind of neural network architecture, called a transformer . The transformer architecture helps foundation models understand unlabeled data and turn an input into an output. The most consequential manifestation of this technology so far is what we know today as \" generative AI .\" So what is generative AI ? The vast topic refers to a subset of AI techniques and methodologies that are designed to generate new content \u2014 in other words, AI applied towards the creation of novel content in the form of images, text, voice, and even programming code. This sharply differs from the goals of more \"traditional\" AI models of the past, which have primarily been focused on the analysis and classification (labeling) of information. Historically, these early pioneering techniques of AI models have progressed from simple probabilistic models into increasingly sophisticated systems, building upon concepts like neural networks and deep learning techniques. Today, technologies like generative AI showcase not only the ability to perform analysis, but also tremendous capacity for creation. Even the creation of application code and automation tasks. The advent of foundation models and generative AI, given their remarkable performance and extensibility to a wide range of tasks, has brought about an inflection point in AI. Recognizing the significance of the moment, IBM enterprise clients are actively evaluating and seeking to incorporate foundation models into critical business workflows and applications \u2014 anything and everything which involves generation, summarization, classification, and many other use cases. IBM-trained watsonx.ai CodeLLM is a Large Language Model (LLM) for programming languages and code, one of the many foundation models available to IBM watsonx.ai \u2014 and then further refined and calibrated for use with specific programming languages like COBOL, Ansible, and others. IBM watsonx Code Assistant is the flagship product for generative AI services, with a variety of options ( for Red Hat Ansible Lightspeed , for Z ) that are tailored to specific client use cases and business goals.","title":"80% of the product development lifecycle will make use of generative AI-derived code by 2025 \u2014Gartner"},{"location":"#_2","text":"","title":""},{"location":"#the-notion-of-automating-the-generation-of-ansible-playbook-code-with-ai-stems-from-the-challenges-and-bottlenecks-often-faced-by-developers-tasked-with-traditional-manual-creation-of-playbooks","text":"IBM watsonx Code Assistant (WCA) is powered by IBM Granite foundation models, based on decoder-only transformer architecture. Granite language models are trained on trusted enterprise data spanning internet, academic, and code \u2014 especially open-source code repositories like GitHub and Ansible Galaxy. IBM Granite is a 20-billion parameter model for code that was trained on 1.6 trillion code tokens. Within these models, IBM performs a comprehensive sweep to filter out sensitive, toxic, and copyright-protected code. Those models are then pre-trained on datasets for automation (Ansible content) and application modernization. The result are highly specialized models that can immediately go to work in service of IBM enterprise client's highest priority use cases. WHAT ARE PLAYBOOKS? Ansible Playbooks instruct Ansible\u2019s automation engine on how to execute tasks in a step-by-step manner. Playbooks defines roles, tasks, handlers, and other configurations; in turn, these attributes allow developers and users to codify complex orchestration scenarios. Conceptually, think of a Playbook as a recipe book for system administration: each recipe (or Playbook) spells out the steps required to achieve a particular system state or to complete a given operation. One of the standout features of Ansible Playbooks is that they are idempotent : executing Playbooks them multiple times on the same system won't create additional \"side effects\" (unintended operations or creation of unwanted artifacts) after the first successful run. This ensures consistency and reliability across deployments of the Red Hat Ansible Automation Platform ( AAP ).","title":"The notion of automating the generation of Ansible Playbook code with AI stems from the challenges and bottlenecks often faced by developers tasked with traditional, manual creation of Playbooks"},{"location":"#_3","text":"","title":""},{"location":"#30-faster-time-to-value-observed-in-it-automation-by-adopting-ibm-watsonx-code-assistant-with-red-hat-ansible-lightspeed","text":"Enterprise clients that are delivering an IT automation practice within their organization can be more efficient, can trust in the accuracy of their AI-generated content, and can upskill their teams faster. Regarding security\u2014 of upmost concern to enterprise organizations \u2014the natural language prompts sent to WCA and the code recommendations returned by WCA are both encrypted (in-transit and at-rest.) The generative AI recommendations are also ephemeral: IBM does not store or retain prompts, recommendations, or code. The prompt is discarded as soon as a recommendation is ready to send back to a client; likewise, that recommendation is never retained by IBM. When there is client data submitted by the user to WCA, such as when a client is looking to perform model customization based on their own datasets (something this training will explore in detail), that data is stored directly within a client-owned Cloud Object Storage instance. The data remains accessible only to the client \u2014 it is impervious to IBM, Red Hat, or any other user besides the client who owns it. There are three core components to the hands-on training environment: Visual Studio Code (VS Code) running on your local machine, connected via VS Code Extensions to... Ansible Automation Platform (AAP) running on the Red Hat cloud, licensed for use with Red Hat Ansible Lightspeed and integrated with... IBM watsonx Code Assistant (WCA) running on IBM Cloud, providing generative AI and model customization Developers and programmers must craft precise, error-free Playbooks which are potentially automating jobs across vast collections of assets or hardware. One of the benefits of automation is being able to perform such tasks at-scale; conversely, this also poses one of the greatest risks of automation \u2014 that if things fail, they can fail rapidly and across vast swathes of IT estate. It should come as no surprise, then, that authoring Playbooks often demands technical expertise and a deep understanding of the targeted systems and services which Ansible is to automate. Generative AI has recently demonstrated proficiency in creating syntactically correct and contextually relevant application code in a variety of programming languages. For example, if trained on a large dataset of Ansible Playbooks, generative AI models can be fine-tuned to understand the nuances of Playbook syntax and structure. An enterprise organization with dozens or hundreds of Playbooks within their IT estate today would have a rich corpus of training data on-hand that could be used to fine-tune AI models that are tailored to the automation needs and programming style or standards of that particular company. As you will see throughout the hands-on training material, generative AI models provide a natural language prompt to users which in turn is understood and translated by the AI models into the necessary Ansible Task code. For example, a user might describe a desired system state in plain language (\"I want a Playbook to install and start the Apache web server\") and the model will generate the appropriate Ansible Tasks for a Playbook. All of this achieved without physically writing code or requiring much programming expertise. Not only does this speed up the automation process by cutting the time needed to author Playbooks, but it also democratizes access to automation in general. Even those within a company with limited Ansible or programming expertise will be able to produce effective Playbooks. There are plenty of caveats of course, and thorough validation and testing of AI-generated code will be needed before being put into production. However, the productivity gains and broadening of skillsets within an organization can be tremendous. And as a whole, generative AI brings the original goals of Red Hat Ansible Automation Platform (the democratization of automation for everything) that much closer to a reality.","title":"30% faster time to value observed in IT automation by adopting IBM watsonx Code Assistant with Red Hat Ansible Lightspeed"},{"location":"#_4","text":"","title":""},{"location":"#the-material-covered-in-this-hands-on-training-is-intended-to-prepare-ibm-clients-with-the-skills-necessary-to-create-ansible-playbook-tasks-using-the-generative-ai-capabilities-of-wca","text":"The curriculum will leverage WCA's generative AI code recommendations for automating cloud-based and infrastructure-based automation tasks. In-depth explanations accompanying Ansible Playbook templates will also explain: How WCA uses natural language prompts , as well as Ansible Playbook contents, to generate contextually-aware Task code recommendations Post-processing capabilities that refine the generative AI suggestions into syntactically correct code (adherent to best practices) How WCA provides content source matching attribution and \"explainability\" for all AI-generated content Leveraging WCA's model tuning capabilities to tailor content and code recommendations to an organization's standards, best practices, and programming styles","title":"The material covered in this hands-on training is intended to prepare IBM clients with the skills necessary to create Ansible Playbook tasks using the generative AI capabilities of WCA"},{"location":"#_5","text":"","title":""},{"location":"#next-steps","text":"In the following section, you will prepare your hands-on lab environment with the necessary services and configurations.","title":"Next steps"},{"location":"customizing/","text":"Precision is key for the disambiguation of natural language prompts In this section, you will experiment with customized Ansible Playbooks and test how changes made to an Ansible Task's natural language descriptions can impact the recommended code produced by IBM watsonx Code Assistant for Red Hat Ansible Lightspeed ( WCA ). UNPREDICTABLE RESULTS FROM GENERATIVE AI & LLMs A consequence of using generative AI and Large Language Models (LLMs) is that the recommended code output of these systems will never be 100% consistent for each and every execution. For this reason, LLMs are referred to as \"non-deterministic\" systems \u2014 as opposed to \"deterministic\" systems. This is both a strength and weakness of LLMs. As you will observe in this module, even a slight modification to the Task description or the smallest change to how a Playbook is structured\u2014 the descriptions used, the variables set, and so on \u2014will influence AI-generated code recommendations. The iterative process that you will go through in this module can be viewed in three different ways: On the one hand, it shows the sensitivity of generative AI models to even the most nuanced change in natural language prompts \u2014 for good or bad. Generative AI can produce tremendous work and that output is further guided along by best practices built-in from Red Hat and IBM. But in the end, the AI can only infer user intent from the natural language descriptions supplied to it. The more clearly a user defines their Task descriptions and intent, the more likely that WCA will correctly generate code which mirrors that intent; conversely, the less precise those descriptions are, the more likely WCA will misinterpret and miss the mark. Precision is key for the disambiguation of natural language prompts. Human feedback and humans-in-the-loop are essential to these formative stages of generative AI. As offerings like WCA mature, the natural language processing capabilities of the service will continue to be refined and improved. Additional packages, functions, and training data from Ansible Galaxy (as well as other sources) are continuously being added to the product's Foundation Models, which will in turn continually improve the AI-generated code recommendations made to users. Feedback can be directly supplied via the WCA extension for VS Code and additional ways to support model training are documented online . By using the Model Tuning capabilities built into IBM watsonx Code Assistant , organizations and users are able to customize the recommendations produced by generative AI, tuning a domain-specific LLM with the organization's own Ansible Playbooks. The content and code recommendations that WCA suggests can be tailored to an organization's standards, best practices, and programming styles. These capabilities will be explored later in this module. The take-away here is that your results may vary : they may differ from the SOLUTION code presented in the steps below. Keep this in mind as you work through the examples in this section and understand that it is not a bug, but rather a consequence of working with generative AI in general. The precision with which a Playbook author describes the automation Task in natural language will determine the accuracy and effectiveness of WCA's generated code recommendations. A template CUSTOM PLAYBOOK #1 YAML file has been prepared for you below. Copy and paste the code from the TEMPLATE tab into a New File... within VS Code Name and save the file as you see fit: for example, customplaybook1.yml HOW TO CREATE NEW YAML PLAYBOOKS Note: You need to copy and paste the contents of the Playbook into a New File... within the same Lightspeed project directory that was used for the previous lab modules in order for the VS Code extension to engage. To create a new YAML Playbook within a VS Code environment: a. Copy the contents of the Playbook to clipboard using the button in the top-right corner of the lab guide code block. b. Return to your VS Code environment. In the top-left corner of the interface, with your Ansible Lightspeed folder selected, click the New File... button. c. Name the file to a description of your choosing, ending with .yml as the filetype. Set it to CustomPlaybook.yml , for example. Save it to one of the directories in the ansible-wca-demo-kit folder. d. Paste the clipboard contents into the YAML file and follow along with the suggestions below. COPY AND PASTE CODE WITHIN THE VM Information \"copied\" to your local machine's clipboard cannot be \"pasted\" directly into the virtual machine (VM) environment or VS Code. If you wish to copy and paste instructions directly from the lab documentation, it is recommended that you open the GitHub instructions inside the VM's web browser (Firefox). This will allow you to copy instructions to the VM's clipboard and paste instructions inside the VS Code editor. ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible CUSTOM PLAYBOOK 1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # CUSTOM PLAYBOOK #1 \u2014 Invoke 2 modules to automatically update 2 types of servers. --- # TASK 1 - name : Update web servers hosts : webservers become : true tasks : - name : Ensure apache is at the latest version - name : Write the apache config file # TASK 2 - name : Update db servers hosts : databases become : true tasks : - name : Ensure postgresql is at the latest version - name : Ensure that postgresql is started The template CUSTOM PLAYBOOK #1 contains two sets of tasks: TASK 1 ( Lines 5-12 ) checks whether or not web server software is up to date and runs the update if necessary TASK 2 ( Lines 15-22 ) checks whether or not database server software is up to date and runs the update if necessary Examine the instruction on Line 12 , which prompts Ansible to create (\"write\") a configuration file for an Apache webserver: - name : Write the apache config file Place your cursor at the end of Line 12 and press Enter to generate WCA-recommended code for the task. Accept the recommendation by pressing Tab . Two tabs are presented below: AI-GENERATED CODE shows the output from running WCA's generative AI capabilities on Line 12 of the unmodified CUSTOM PLAYBOOK #1 YAML template. SOLUTION CODE shows the expected (correct) code for performing the task that was written by a human programmer. In theory, the AI-generated code should be as good\u2014 or even superior to \u2014the manually-written solution code. AI-GENERATED CODE SOLUTION CODE 1 2 3 4 5 6 7 - name : Write the apache config file ansible.builtin.template : src : templates/apache.conf.j2 dest : /etc/apache2/sites-available/000-default.conf owner : root group : root mode : '0644' 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" As you can see, the AI-GENERATED CODE recommendations satisfy some of the requests, but also miss the mark in a few areas. When compared to the SOLUTION CODE tab: Both tabs appropriately utilize the ansible.builtin.template Module, which for this request is absolutely correct. Interesting fact: earlier (circa 2023) versions of WCA produced code recommendations for the same task as this one, which did not align with the expected solution. Instead, the recommendation was for the ansible.builtin.copy Module to invoke content: \"{{ _content_ }}\" , which is not correct. This speaks to the continuously improving capabilities of the WCA and IBM Granite models. AI-GENERATED CODE recommended including statements that explicitly set owner: root and group: root , which are both appropriate when permissions are set to mode: '0644' . While not strictly necessary, these additional statements arguably are an improvement over the SOLUTION CODE results. It's also worth noting that the request to write the apache config file did not explicitly request mode: '0644' in the natural language description, but WCA nevertheless recommended it (post-processing) as this is a best practice for deploying Apache webservers. The src and dest variables are not in agreement across the AI-GENERATED CODE and SOLUTION CODE tabs. This is an area for improvement. The natural language description wasn't precise about these details; therefore, this is an opportunity where more detailed and verbose instructions could better steer the recommendations WCA returns back with. In general, the more ambiguous the Task description, the greater the likelihood that WCA will misinterpret the author's intent and suggest unwanted Ansible automation jobs. To help disambiguate our intention, Playbook authors should use more precise natural language terms and descriptions. Delete the WCA-suggested lines of code from Step 4 from the Playbook. Re-write the description on Line 12 to the following code block, then press Enter and Tab to accept the new WCA code recommendations. Take note of the much more precise language used to describe the src and dest variables. - name : Write the apache config file where src equals httpd.j2 and dest equals httpd.config The resulting WCA-recommended code should be similar to the AI-GENERATED CODE tab below. When compared to the SOLUTION CODE tab: The src: httpd.j2 recommendation in the AI-GENERATED CODE tab is an exact match to the natural language description set in Step 6 , and only slightly different (in terms of the directory path used) to the src: /srv/httpd.j2 variable in the SOLUTION CODE tab. The dest: /etc/httpd/conf/httpd.conf recommendation in the AI-GENERATER CODE tab, unfortunately, still deviates from the httpd.config (not the same as httpd.conf ) destination that was requested in the natural language description. Close, but still far from exact and not matching our specifications. However, it's a vast improvement over the dest: /etc/apache2/sites-available/000-default.conf destination that was recommended as a result of Step 4 's more ambiguous task description. Perplexingly, the mode: '0644' recommendation that was made previously in Step 4 has been left out of the suggested task code. We can speculate as to why\u2014 perhaps the more precise natural language description made in Step 6 prompted WCA to only generate code for exactly what was specified \u2014but the \"black box\" nature of generative AI means that we cannot know for certain. Perhaps with another, even more precise iteration the AI-GENERATED CODE will match the SOLUTION CODE ? AI-GENERATED CODE SOLUTION CODE 1 2 3 4 - name : Write the apache config file where src equals httpd.j2 and dest equals httpd.config ansible.builtin.template : src : httpd.j2 dest : /etc/httpd/conf/httpd.conf 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" Iterate on the lessons learned in Step 7 and modify the task description to include more details on the permissions applied to the Apache webserver. Delete the WCA-suggested lines of code from Step 6 from the Playbook. Re-write the description on Line 12 to the following code block, then press Enter and Tab to accept the new WCA code recommendations. Take note of the much more precise language used to describe the mode variable. - name : Write the apache config file where src equals httpd.j2 and dest equals httpd.config and mode equals 0644 Once again, the resulting WCA-recommended code should be similar to the AI-GENERATED CODE tab below. When compared to the SOLUTION CODE tab: WCA correctly picked up on the mode: '0644' request made in the modified task description. There is now alignment between the two tabs. With only a few iterations and by disambiguating the natural language description of the Ansible Task to be performed, the code recommendations produced by WCA have been markedly improved. AI-GENERATED CODE SOLUTION CODE 1 2 3 4 5 - name : Write the apache config file where src equals httpd.j2 and dest equals httpd.config and mode equals 0644 ansible.builtin.template : src : httpd.j2 dest : /etc/httpd/conf/httpd.conf mode : '0644' 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" Model customization Since every organization is different, WCA allows users to customize the AI model output to your organization's unique Ansible Playbooks. This allows for personalized code recommendations that are a better fit to your business' unique needs and more reflective of the programming standards set within your organization. In this scenario, your organization has its own set of Ansible Playbooks that leverage your preferred cloud provider, that uses specific Ansible Modules to manage OpenShift clusters. Open the tuning-example.yml Playbook located within the Model Customization subdirectory of the hands-on lab templates. The full directory address, as well as the Playbook code, are encapsulated in the following code block. ~/ansible-wca-demo-kit/Model Customization/tuning-example.yml 1 2 3 4 5 6 --- - name : Deploy infrastructure hosts : all tasks : - name : Create an OpenShift cluster ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible Before performing any model tuning tasks, try generating code recommendations for the OpenShift cluster creation task by placing your cursor at the end of Line 6 , hitting Enter , and then accepting the default recommendations by hitting Tab . The resulting code recommendations\u2014 displayed below \u2014represent the standard, unmodified output from WCA's IBM Granite base models. When using the standard IBM Granite model recommendations, it recommends making use of the ansible.builtin.command Ansible Module \u2014 which is a standard, best-practice way to perform these types of deployments. However, your particular organization (and the public cloud provider they use for deploying OpenShift clusters) might require the use of different Ansible Modules. The following steps will explore how to tailor WCA-generated code blocks to the unique needs of a business. STANDARD IBM GRANITE MODEL RECOMMENDATIONS 1 2 3 4 5 6 7 8 9 10 --- - name : Deploy infrastructure hosts : all tasks : - name : Create an OpenShift cluster ansible.builtin.command : oadm create-cluster --wait=false --name=openshift-cluster register : oadm_create_cluster changed_when : \"'created' in oadm_create_cluster.stdout\" failed_when : \"'already exists' not in oadm_create_cluster.stdout\" DATA PREPARATION & MODEL TRAINING Given the scope and time available for this hands-on training, participants will not be manually creating the training data or training models themselves. Instead, you will utilize a prepared customized model ( Model ID ) and experiment from Step 12 and onwards with how the tuned Model ID impacts WCA's code recommendations. The process of building Ansible training data and tuning customized models for generative AI is potentially a complex and time-consuming one. For example, the model tuning employed in the steps ahead for the creation of an OpenShift cluster according to an enterprise organization's specific standards requires approximately 4 hours to train and generate a customized AI model. In preparation for model tuning, an organization or user can transform their existing Playbooks into training data for WCA using the open-source Ansible Parser Tool . The tooling analyzes Ansible Playbooks and generates a single JSONL ( ftdata.jsonl formatted) file that can be uploaded to WCA's model tuning studio for developing customized AI models. The process of calibrating and running the Ansible Parser Tool is time-consuming and potentially quite complex, depending on the scope of Playbooks that an organization wishes to analyze and prepare for model tuning. This falls outside the scope of the hands-on material for this training. For the purposes of demonstration, a preconfigured openshift-tune-micro.jsonl was used for the model tuning example. With the Ansible training data prepared, the IBM watsonx Code Assistant on IBM Cloud service was configured to execute a new model tuning experiment. WCA provides a graphical user experience [A] to streamline the model tuning and customization process Tuning experiment name [B] set to Tuning Experiment and confirmed with Create tuning experiment [C] The openshift-tune-micro.jsonl training data from Ansible Parser Tool is uploaded into WCA [D] A summary of metrics\u2014 including parameters for sampling and Ansible modules \u2014are displayed within the model tuning wizard before Start tuning [E] is selected to kick off the model tuning operating After the tuning operation has ended, a training loss graph reveals how accurate the model's predictions are over the training data set, across multiple tuning cycles As the number of tuning cycles increase, the training loss rating will tend to decrease Model tuning for these particular metrics and parameters takes approximately 4 hours to complete CLICK TO EXPAND \u2014 ACCOMPANYING SCREENSHOTS To override the IBM Granite base model recommendations, you must provide a pointer to a customized Model ID (prepared and hosted earlier on WCA) using the VS Code extension. Model ID : 7ac243b2-0897-4ea8-b208-b55fd145cdb3<|sepofid|>6404b81d-0638-4b7a-9b7c-786e26cf3a11 Look for Ansible under the Installed services in the Extensions panel. Click the Manage (\"cogwheel\") icon located just to the right of the Ansible tile From the drop-down options, click Extension Settings [A] Within the search bar at the top of the panel, add the text Model to filter the results [B] Copy and paste the Model ID value (above) into the empty Ansible > Lightspeed: Model ID Override field [C] , then click the X in the top-left corner of the panel to save and exit Extension Settings With the tuned model, WCA will recommend code using modules, functions, and other details specific to your organization's private IT environment. Return to the tuning-example.yml Playbook from Step 10 and delete the code recommendations generated in Step 11 Regenerate the code recommendations for the task by placing your cursor at the end of Line 6 , hitting Enter , and then Tab Observe how the tuned Model ID has modified WCA's code recommendations by toggling between the TUNED MODEL and STANDARD MODEL tabs below TUNED MODEL STANDARD MODEL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 --- - name : Deploy infrastructure hosts : all tasks : - name : Create an OpenShift cluster register : cluster_create_output when : cluster_output.rc != 0 ibm.cloudcollection.ibm_container_cluster : name : test_cluster datacenter : \"{{ datacenter }}\" machine_type : \"{{ machine_type }}\" hardware : \"{{ hardware }}\" kube_version : 4.14_openshift public_vlan_id : \"{{ public_vlan_id }}\" private_vlan_id : \"{{ private_vlan_id }}\" default_pool_size : \"{{ default_worker_pool_size }}\" entitlement : \"{{ entitlement }}\" 1 2 3 4 5 6 7 8 9 10 --- - name : Deploy infrastructure hosts : all tasks : - name : Create an OpenShift cluster ansible.builtin.command : oadm create-cluster --wait=false --name=openshift-cluster register : oadm_create_cluster changed_when : \"'created' in oadm_create_cluster.stdout\" failed_when : \"'already exists' not in oadm_create_cluster.stdout\" Using the tuned Model ID , WCA has returned a recommendation to use the ibm.cloudcollection.ibm_container_cluster Module for the IBM Cloud, instead of the standard ansible.builtin.command Module from Step 11 . This more accurately conforms to the organization's Ansible automation standards and requirements. REMOVE THE CUSTOMIZED MODEL ID WHEN FINISHED Remember to clear the Ansible > Lightspeed: Model ID Override in the Extension Settings once you have completed Step 13 , otherwise all subsequent code generation requests made to WCA will be produced using the customized AI model. Next steps That concludes the hands-on components for IBM watsonx Code Assistant for Red Hat Ansible Lightspeed - Generative AI Training . At this time, you are invited to follow the accreditation process to formalize your achievement.","title":"Task Description Tuning and Model Customization"},{"location":"customizing/#precision-is-key-for-the-disambiguation-of-natural-language-prompts","text":"","title":"Precision is key for the disambiguation of natural language prompts"},{"location":"customizing/#_1","text":"In this section, you will experiment with customized Ansible Playbooks and test how changes made to an Ansible Task's natural language descriptions can impact the recommended code produced by IBM watsonx Code Assistant for Red Hat Ansible Lightspeed ( WCA ). UNPREDICTABLE RESULTS FROM GENERATIVE AI & LLMs A consequence of using generative AI and Large Language Models (LLMs) is that the recommended code output of these systems will never be 100% consistent for each and every execution. For this reason, LLMs are referred to as \"non-deterministic\" systems \u2014 as opposed to \"deterministic\" systems. This is both a strength and weakness of LLMs. As you will observe in this module, even a slight modification to the Task description or the smallest change to how a Playbook is structured\u2014 the descriptions used, the variables set, and so on \u2014will influence AI-generated code recommendations. The iterative process that you will go through in this module can be viewed in three different ways: On the one hand, it shows the sensitivity of generative AI models to even the most nuanced change in natural language prompts \u2014 for good or bad. Generative AI can produce tremendous work and that output is further guided along by best practices built-in from Red Hat and IBM. But in the end, the AI can only infer user intent from the natural language descriptions supplied to it. The more clearly a user defines their Task descriptions and intent, the more likely that WCA will correctly generate code which mirrors that intent; conversely, the less precise those descriptions are, the more likely WCA will misinterpret and miss the mark. Precision is key for the disambiguation of natural language prompts. Human feedback and humans-in-the-loop are essential to these formative stages of generative AI. As offerings like WCA mature, the natural language processing capabilities of the service will continue to be refined and improved. Additional packages, functions, and training data from Ansible Galaxy (as well as other sources) are continuously being added to the product's Foundation Models, which will in turn continually improve the AI-generated code recommendations made to users. Feedback can be directly supplied via the WCA extension for VS Code and additional ways to support model training are documented online . By using the Model Tuning capabilities built into IBM watsonx Code Assistant , organizations and users are able to customize the recommendations produced by generative AI, tuning a domain-specific LLM with the organization's own Ansible Playbooks. The content and code recommendations that WCA suggests can be tailored to an organization's standards, best practices, and programming styles. These capabilities will be explored later in this module. The take-away here is that your results may vary : they may differ from the SOLUTION code presented in the steps below. Keep this in mind as you work through the examples in this section and understand that it is not a bug, but rather a consequence of working with generative AI in general. The precision with which a Playbook author describes the automation Task in natural language will determine the accuracy and effectiveness of WCA's generated code recommendations. A template CUSTOM PLAYBOOK #1 YAML file has been prepared for you below. Copy and paste the code from the TEMPLATE tab into a New File... within VS Code Name and save the file as you see fit: for example, customplaybook1.yml HOW TO CREATE NEW YAML PLAYBOOKS Note: You need to copy and paste the contents of the Playbook into a New File... within the same Lightspeed project directory that was used for the previous lab modules in order for the VS Code extension to engage. To create a new YAML Playbook within a VS Code environment: a. Copy the contents of the Playbook to clipboard using the button in the top-right corner of the lab guide code block. b. Return to your VS Code environment. In the top-left corner of the interface, with your Ansible Lightspeed folder selected, click the New File... button. c. Name the file to a description of your choosing, ending with .yml as the filetype. Set it to CustomPlaybook.yml , for example. Save it to one of the directories in the ansible-wca-demo-kit folder. d. Paste the clipboard contents into the YAML file and follow along with the suggestions below. COPY AND PASTE CODE WITHIN THE VM Information \"copied\" to your local machine's clipboard cannot be \"pasted\" directly into the virtual machine (VM) environment or VS Code. If you wish to copy and paste instructions directly from the lab documentation, it is recommended that you open the GitHub instructions inside the VM's web browser (Firefox). This will allow you to copy instructions to the VM's clipboard and paste instructions inside the VS Code editor. ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible CUSTOM PLAYBOOK 1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # CUSTOM PLAYBOOK #1 \u2014 Invoke 2 modules to automatically update 2 types of servers. --- # TASK 1 - name : Update web servers hosts : webservers become : true tasks : - name : Ensure apache is at the latest version - name : Write the apache config file # TASK 2 - name : Update db servers hosts : databases become : true tasks : - name : Ensure postgresql is at the latest version - name : Ensure that postgresql is started The template CUSTOM PLAYBOOK #1 contains two sets of tasks: TASK 1 ( Lines 5-12 ) checks whether or not web server software is up to date and runs the update if necessary TASK 2 ( Lines 15-22 ) checks whether or not database server software is up to date and runs the update if necessary Examine the instruction on Line 12 , which prompts Ansible to create (\"write\") a configuration file for an Apache webserver: - name : Write the apache config file Place your cursor at the end of Line 12 and press Enter to generate WCA-recommended code for the task. Accept the recommendation by pressing Tab . Two tabs are presented below: AI-GENERATED CODE shows the output from running WCA's generative AI capabilities on Line 12 of the unmodified CUSTOM PLAYBOOK #1 YAML template. SOLUTION CODE shows the expected (correct) code for performing the task that was written by a human programmer. In theory, the AI-generated code should be as good\u2014 or even superior to \u2014the manually-written solution code. AI-GENERATED CODE SOLUTION CODE 1 2 3 4 5 6 7 - name : Write the apache config file ansible.builtin.template : src : templates/apache.conf.j2 dest : /etc/apache2/sites-available/000-default.conf owner : root group : root mode : '0644' 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" As you can see, the AI-GENERATED CODE recommendations satisfy some of the requests, but also miss the mark in a few areas. When compared to the SOLUTION CODE tab: Both tabs appropriately utilize the ansible.builtin.template Module, which for this request is absolutely correct. Interesting fact: earlier (circa 2023) versions of WCA produced code recommendations for the same task as this one, which did not align with the expected solution. Instead, the recommendation was for the ansible.builtin.copy Module to invoke content: \"{{ _content_ }}\" , which is not correct. This speaks to the continuously improving capabilities of the WCA and IBM Granite models. AI-GENERATED CODE recommended including statements that explicitly set owner: root and group: root , which are both appropriate when permissions are set to mode: '0644' . While not strictly necessary, these additional statements arguably are an improvement over the SOLUTION CODE results. It's also worth noting that the request to write the apache config file did not explicitly request mode: '0644' in the natural language description, but WCA nevertheless recommended it (post-processing) as this is a best practice for deploying Apache webservers. The src and dest variables are not in agreement across the AI-GENERATED CODE and SOLUTION CODE tabs. This is an area for improvement. The natural language description wasn't precise about these details; therefore, this is an opportunity where more detailed and verbose instructions could better steer the recommendations WCA returns back with. In general, the more ambiguous the Task description, the greater the likelihood that WCA will misinterpret the author's intent and suggest unwanted Ansible automation jobs. To help disambiguate our intention, Playbook authors should use more precise natural language terms and descriptions. Delete the WCA-suggested lines of code from Step 4 from the Playbook. Re-write the description on Line 12 to the following code block, then press Enter and Tab to accept the new WCA code recommendations. Take note of the much more precise language used to describe the src and dest variables. - name : Write the apache config file where src equals httpd.j2 and dest equals httpd.config The resulting WCA-recommended code should be similar to the AI-GENERATED CODE tab below. When compared to the SOLUTION CODE tab: The src: httpd.j2 recommendation in the AI-GENERATED CODE tab is an exact match to the natural language description set in Step 6 , and only slightly different (in terms of the directory path used) to the src: /srv/httpd.j2 variable in the SOLUTION CODE tab. The dest: /etc/httpd/conf/httpd.conf recommendation in the AI-GENERATER CODE tab, unfortunately, still deviates from the httpd.config (not the same as httpd.conf ) destination that was requested in the natural language description. Close, but still far from exact and not matching our specifications. However, it's a vast improvement over the dest: /etc/apache2/sites-available/000-default.conf destination that was recommended as a result of Step 4 's more ambiguous task description. Perplexingly, the mode: '0644' recommendation that was made previously in Step 4 has been left out of the suggested task code. We can speculate as to why\u2014 perhaps the more precise natural language description made in Step 6 prompted WCA to only generate code for exactly what was specified \u2014but the \"black box\" nature of generative AI means that we cannot know for certain. Perhaps with another, even more precise iteration the AI-GENERATED CODE will match the SOLUTION CODE ? AI-GENERATED CODE SOLUTION CODE 1 2 3 4 - name : Write the apache config file where src equals httpd.j2 and dest equals httpd.config ansible.builtin.template : src : httpd.j2 dest : /etc/httpd/conf/httpd.conf 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" Iterate on the lessons learned in Step 7 and modify the task description to include more details on the permissions applied to the Apache webserver. Delete the WCA-suggested lines of code from Step 6 from the Playbook. Re-write the description on Line 12 to the following code block, then press Enter and Tab to accept the new WCA code recommendations. Take note of the much more precise language used to describe the mode variable. - name : Write the apache config file where src equals httpd.j2 and dest equals httpd.config and mode equals 0644 Once again, the resulting WCA-recommended code should be similar to the AI-GENERATED CODE tab below. When compared to the SOLUTION CODE tab: WCA correctly picked up on the mode: '0644' request made in the modified task description. There is now alignment between the two tabs. With only a few iterations and by disambiguating the natural language description of the Ansible Task to be performed, the code recommendations produced by WCA have been markedly improved. AI-GENERATED CODE SOLUTION CODE 1 2 3 4 5 - name : Write the apache config file where src equals httpd.j2 and dest equals httpd.config and mode equals 0644 ansible.builtin.template : src : httpd.j2 dest : /etc/httpd/conf/httpd.conf mode : '0644' 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\"","title":""},{"location":"customizing/#_2","text":"","title":""},{"location":"customizing/#model-customization","text":"Since every organization is different, WCA allows users to customize the AI model output to your organization's unique Ansible Playbooks. This allows for personalized code recommendations that are a better fit to your business' unique needs and more reflective of the programming standards set within your organization. In this scenario, your organization has its own set of Ansible Playbooks that leverage your preferred cloud provider, that uses specific Ansible Modules to manage OpenShift clusters. Open the tuning-example.yml Playbook located within the Model Customization subdirectory of the hands-on lab templates. The full directory address, as well as the Playbook code, are encapsulated in the following code block. ~/ansible-wca-demo-kit/Model Customization/tuning-example.yml 1 2 3 4 5 6 --- - name : Deploy infrastructure hosts : all tasks : - name : Create an OpenShift cluster ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible Before performing any model tuning tasks, try generating code recommendations for the OpenShift cluster creation task by placing your cursor at the end of Line 6 , hitting Enter , and then accepting the default recommendations by hitting Tab . The resulting code recommendations\u2014 displayed below \u2014represent the standard, unmodified output from WCA's IBM Granite base models. When using the standard IBM Granite model recommendations, it recommends making use of the ansible.builtin.command Ansible Module \u2014 which is a standard, best-practice way to perform these types of deployments. However, your particular organization (and the public cloud provider they use for deploying OpenShift clusters) might require the use of different Ansible Modules. The following steps will explore how to tailor WCA-generated code blocks to the unique needs of a business. STANDARD IBM GRANITE MODEL RECOMMENDATIONS 1 2 3 4 5 6 7 8 9 10 --- - name : Deploy infrastructure hosts : all tasks : - name : Create an OpenShift cluster ansible.builtin.command : oadm create-cluster --wait=false --name=openshift-cluster register : oadm_create_cluster changed_when : \"'created' in oadm_create_cluster.stdout\" failed_when : \"'already exists' not in oadm_create_cluster.stdout\" DATA PREPARATION & MODEL TRAINING Given the scope and time available for this hands-on training, participants will not be manually creating the training data or training models themselves. Instead, you will utilize a prepared customized model ( Model ID ) and experiment from Step 12 and onwards with how the tuned Model ID impacts WCA's code recommendations. The process of building Ansible training data and tuning customized models for generative AI is potentially a complex and time-consuming one. For example, the model tuning employed in the steps ahead for the creation of an OpenShift cluster according to an enterprise organization's specific standards requires approximately 4 hours to train and generate a customized AI model. In preparation for model tuning, an organization or user can transform their existing Playbooks into training data for WCA using the open-source Ansible Parser Tool . The tooling analyzes Ansible Playbooks and generates a single JSONL ( ftdata.jsonl formatted) file that can be uploaded to WCA's model tuning studio for developing customized AI models. The process of calibrating and running the Ansible Parser Tool is time-consuming and potentially quite complex, depending on the scope of Playbooks that an organization wishes to analyze and prepare for model tuning. This falls outside the scope of the hands-on material for this training. For the purposes of demonstration, a preconfigured openshift-tune-micro.jsonl was used for the model tuning example. With the Ansible training data prepared, the IBM watsonx Code Assistant on IBM Cloud service was configured to execute a new model tuning experiment. WCA provides a graphical user experience [A] to streamline the model tuning and customization process Tuning experiment name [B] set to Tuning Experiment and confirmed with Create tuning experiment [C] The openshift-tune-micro.jsonl training data from Ansible Parser Tool is uploaded into WCA [D] A summary of metrics\u2014 including parameters for sampling and Ansible modules \u2014are displayed within the model tuning wizard before Start tuning [E] is selected to kick off the model tuning operating After the tuning operation has ended, a training loss graph reveals how accurate the model's predictions are over the training data set, across multiple tuning cycles As the number of tuning cycles increase, the training loss rating will tend to decrease Model tuning for these particular metrics and parameters takes approximately 4 hours to complete CLICK TO EXPAND \u2014 ACCOMPANYING SCREENSHOTS To override the IBM Granite base model recommendations, you must provide a pointer to a customized Model ID (prepared and hosted earlier on WCA) using the VS Code extension. Model ID : 7ac243b2-0897-4ea8-b208-b55fd145cdb3<|sepofid|>6404b81d-0638-4b7a-9b7c-786e26cf3a11 Look for Ansible under the Installed services in the Extensions panel. Click the Manage (\"cogwheel\") icon located just to the right of the Ansible tile From the drop-down options, click Extension Settings [A] Within the search bar at the top of the panel, add the text Model to filter the results [B] Copy and paste the Model ID value (above) into the empty Ansible > Lightspeed: Model ID Override field [C] , then click the X in the top-left corner of the panel to save and exit Extension Settings With the tuned model, WCA will recommend code using modules, functions, and other details specific to your organization's private IT environment. Return to the tuning-example.yml Playbook from Step 10 and delete the code recommendations generated in Step 11 Regenerate the code recommendations for the task by placing your cursor at the end of Line 6 , hitting Enter , and then Tab Observe how the tuned Model ID has modified WCA's code recommendations by toggling between the TUNED MODEL and STANDARD MODEL tabs below TUNED MODEL STANDARD MODEL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 --- - name : Deploy infrastructure hosts : all tasks : - name : Create an OpenShift cluster register : cluster_create_output when : cluster_output.rc != 0 ibm.cloudcollection.ibm_container_cluster : name : test_cluster datacenter : \"{{ datacenter }}\" machine_type : \"{{ machine_type }}\" hardware : \"{{ hardware }}\" kube_version : 4.14_openshift public_vlan_id : \"{{ public_vlan_id }}\" private_vlan_id : \"{{ private_vlan_id }}\" default_pool_size : \"{{ default_worker_pool_size }}\" entitlement : \"{{ entitlement }}\" 1 2 3 4 5 6 7 8 9 10 --- - name : Deploy infrastructure hosts : all tasks : - name : Create an OpenShift cluster ansible.builtin.command : oadm create-cluster --wait=false --name=openshift-cluster register : oadm_create_cluster changed_when : \"'created' in oadm_create_cluster.stdout\" failed_when : \"'already exists' not in oadm_create_cluster.stdout\" Using the tuned Model ID , WCA has returned a recommendation to use the ibm.cloudcollection.ibm_container_cluster Module for the IBM Cloud, instead of the standard ansible.builtin.command Module from Step 11 . This more accurately conforms to the organization's Ansible automation standards and requirements. REMOVE THE CUSTOMIZED MODEL ID WHEN FINISHED Remember to clear the Ansible > Lightspeed: Model ID Override in the Extension Settings once you have completed Step 13 , otherwise all subsequent code generation requests made to WCA will be produced using the customized AI model.","title":"Model customization"},{"location":"customizing/#_3","text":"","title":""},{"location":"customizing/#next-steps","text":"That concludes the hands-on components for IBM watsonx Code Assistant for Red Hat Ansible Lightspeed - Generative AI Training . At this time, you are invited to follow the accreditation process to formalize your achievement.","title":"Next steps"},{"location":"generating/","text":"Generating Code with IBM watsonx Code Assistant for Red Hat Ansible Lightspeed An Ansible Task is a statement in Ansible's automation script (the YAML-based Playbooks you will be working with) that declares a single action to be executed. This might be installing a package, copying a file, or shutting down a service on a remote machine. Each Task represents an idempotent operation (an action that can be repeated multiple times and deliver the same result every time) that aligns the remote managed node to the specified state. Idempotent operations also ensure consistency across multiple executions, guaranteeing the same steps are taken on each execution of the task. At the time of publication, IBM watsonx Code Assistant for Red Hat Ansible Lightspeed ( WCA ) will only generate code for Ansible Tasks , including both single task and multi-task automation. Once you have learned the fundamentals of generating Task code blocks, you'll be ready to shape and tailor the AI-generated code recommendations using WCA's model tuning capabilities. Generating code for single task Ansible operations The process of creating AI-generated code recommendations is as simple as modifying the natural language (plain English) Task descriptions of an action that is to be executed, which always start with - name: and are followed by some description of the task to be performed. Ansible Tasks are often preceded with some # comments or documentation. After the natural language description of the automation Task has been set by the user, WCA handles the rest. WCA is also capable of generating multiple Ansible Tasks from more complex natural language descriptions\u2014 what is referred to as multi-task code generation \u2014which you will experiment with later in this module. However, to get started, let's begin with the basics of generating code for single task use cases. Begin by opening the install_cockpit_single-task.yml Playbook from the list of assets in the Explorer browser. Click the Explorer tab from the left-hand interface [A] Drill down into the Install and configure Cockpit using Ansible subdirectory [B] Double-click the install_cockpit_single-task.yml Playbook A replica of the Playbook code is also included below in the documentation The red highlighting within the editor reminds users that the tasks: section contains no valid -name: task definitions. This is part of WCA's code validation process which runs automatically and alerts users to syntax errors in their code. You can safely ignore these warnings for now, as you will be un-commenting and generating valid -name: task definitions in the following steps. ~/Documents/ansible-wca-demo-kit/install and configure Cockpit using Ansible/install_cockpit_single-task.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 --- - name : Install and configure Cockpit hosts : rhel become : true # module_defaults: # ansible.builtin.service: # enabled: true # state: started tasks : # TASK 1 # # 1a. Uncomment task description below and generate a task suggestion. # # Note - The suggestion included Ansible best practices by using Fully Qualified Collection name. # - name: Install cockpit package # TASK 2 # # 2a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used \"ansible.builtin.template\" module based on the \".j2\" file extension. # # Note - The suggestion set the file permissions (\"0644\"), owner, and group based on Ansible best practices. # - name: Copy cockpit.conf.j2 to /etc/cockpit # TASK 3 # # 3a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used the generic \"Start and enable service\" prompt # # and full Playbook context to infer the recommendation should start the \"cockpit\" service. # # 3b. Uncomment the \"module_defaults\" section at the top of the Playbook. # # 3c. Clear current task suggestion and request updated suggestion. # # Note - Ansible Lightspeed used the full Playbook context and evaluated the \"module_defaults\" # # when generating a suggestion. # # The updated suggestion no longer includes \"enabled:\" and \"state:\" arguments. # - name: Start and enable service # TASK 4 # # 4a. Uncomment task description below and generate an Ansible Playbook task suggestion. # # 4b. Save the Playbook. # - name: Wait 15 seconds port 9090 The install_cockpit_single-task.yml Playbook code above warrants some explanation before we move on with making AI-generated modifications to it: Line 2 essentially marks the beginning of the Playbook instructions, the purpose of which is to automate the process of installing and configuring Cockpit for Red Hat Ansible. Lines 3-4 define variables that will remain static throughout the remainder of the Playbook. These variables will be referenced by the AI-generated code suggestions at a later stage. This is a key capability of the offering and one which you will explore in much finer details later on in this module. Lines 6-9 are variables which have been commented out and therefore are invisible to the execution of the Ansible script and not examined by WCA for context when generating code recommendations. You will experiment with how removing the # comment blocks impacts the recommendations of task block code. \"Uncommenting\" these lines of code will make them viable for execution and these lines will afterwards be considered as valid Playbook \"context\" for AI code generation. Locate TASK 1 on Line 15 of the YAML file, which handles installation of Cockpit for Ansible. Cockpit is an interactive server administration interface that provides a graphical overview of statistics and configurations for a system or systems within a network. # - name: Install cockpit package Pay attention to the indentation and characters used on Line 15 , which in sequence from left to right are as follows: begins with a Tab indentation a # character to \"comment out\" the line contents a whitespace Space character - name: which signifies the start of a Task definition and finally the natural language description of the Task INDENTATION LEVELS AND WHITESPACE Similarly to Python, Ansible and YAML-based Playbooks are very sensitive to whitespacing and indentation. Indentations (such as the Tab in this example) denote different hierarchies and code nesting levels within the YAML structure. You may use Space instead of Tab if you prefer, but be sure to use indentations consistently : choose to use either Tab or Space for indenting lines of code, and do not interchange between the two. To generate code for TASK 1 using WCA, first uncomment the line of code (remove # characters from the start of a line). Highlight the line(s) of code you wish to uncomment and then press Cmd + ? for macOS or Ctrl + ? for Windows You can repeat those keystrokes with the line(s) selected to toggle between commenting or uncommenting lines of code Tip: commented out lines of code in VS Code will appear as green text Afterwards, Line 15 should look like the following \u2014 beginning with a single Tab : - name : Install cockpit package Now you are ready to begin generating code. Place your cursor on Line 15 and hit Enter Wait for WCA to engage and generate the suggested (in grey, italicized text ) code block for executing the task This temporary code suggestion is entirely generated by AI As a user, you have the option to either: Accept the code recommendation as-given by pressing Tab Modify the recommended code by highlighting and replacing the italicized text ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible Hit Tab to accept the suggested code and then compare with the SOLUTION tab below. TEMPLATE SOLUTION # TASK 1 - name : Install cockpit package # TASK 1 - name : Install cockpit package ansible.builtin.package : name : cockpit state : present As part of the plain-text description of the Task, WCA was asked to include the cockpit Role, part of the Red Hat Enterprise Linux System Roles Certified Content Collection. The AI-generated code suggestion invoked a Fully Qualified Collection Name ( FQCN ) - ansible.builtin.package Making use of FQCNs where possible is a recommended best practice and is a prime example of the many ways in which the offering infuses post-processing capabilities within the AI-generated code produced by WCA. Additional examples of infusing best-practices into AI-generated code recommendations can be found in TASK 2 ( Line 21 of the unmodified template or Line 25 after Step 5 ): Uncomment - name: Copy cockpit.conf.j2 to /etc/cockpit Hit Enter to generate the task code recommendation and accept the AI-suggested code (without modifications) by pressing Tab Compare your results with the SOLUTION tab below TEMPLATE SOLUTION # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' The AI-generated code recommendation will copy cockpit.conf to the target host. Take note of the fact that the recommendation included the mode: argument and set the Linux file permissions to 0644 , neither of which were things explicitly requested in the Task -name description, but are both additions which adhere to best practices around defining Ansible automaton tasks. Setting a file permission to 0644 specifies read and write permissions for User and Group levels within the Linux OS, and provides only read permissions to all others. These additional recommendations stem from a robust example of setting file permissions for the ansible.builtin.copy module, a recommended best practice from the Ansible Galaxy and Red Hat communities that WCA included in the AI-generated code as well. Generating code for multi-task Ansible operations Up to this point, we've kept a narrow aperture on AI-generated recommendations for single tasks \u2014 examining and experimenting with generating Ansible code task by task, one at a time. However, a powerful WCA feature is the ability to combine multiple task descriptions into a single natural language prompt; in turn, WCA is able to parse that instruction, decompose the instruction into discrete Ansible Task parts, and return a complete code recommendation for achieving the author's intended goal. Synatically, multiple tasks are combined into a single natural language expression through the use of ampersand ( % ) characters. Simply write out all the automation task descriptions on a single line, separating each description with a % character. The line must also begin with a # character for reasons that will be explained shortly. To illustrate, let's look at a multi-task Ansible Playbook: install_cockpit_multi-task.yml The contents of this Playbook should look familiar to you already: it is essentially the same Playbook examined in Steps 1-6 ( install_cockpit_single-task.yml ), re-written in an equivalent multi-task expression Each of the Task descriptions from the previous Playbook have been consolidated into a single description on Line 12 , separated by % characters ~/Documents/ansible-wca-demo-kit/install and configure Cockpit using Ansible/install_cockpit_multi-task.yml 1 2 3 4 5 6 7 8 9 10 11 12 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : # Install cockpit package & Copy cockpit.conf.j2 to /etc/cockpit & Start and enable service & Wait 15 seconds port 9090 There are two crucial distinctions between single task and multi-task code generation: formatting and execution. Formatting : Notice that Line 12 does not begin with -name: , as was the case with single task descriptions Execution : In order to generate AI code recommendations for multi-task descriptions, Line 12 must stay commented out (the # needs to remain at the start of the line) What is the rationale behind this? When WCA's generative AI capabilities parse Line 12 , its output will include multiple -name: tasks, each containing potentially multiple lines of instructions, based on how many % -delineated task descriptions are included on the line. Therefore, the way in which the code generation step is executed on Line 12 is a consequence of the formatting decision. Execution of a code generation step on a commented-out ( # ) line containing % delineators is recognized by WCA as a unique case that will be acted upon as a multi-task statement. Place your cursor at the end of Line 12 , and without removing the # character, press Enter to execute the code generation step. Be aware that generating code for multi-task descriptions will take longer compared to a single task. Compare the MULTI-TASK solution tab with the SINGLE TASK solution (copied over from Step 6 ). How did the multi-task code generation fare compared to the single task approach? MULTI-TASK SINGLE TASK 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : - name : Install cockpit package ansible.builtin.package : name : cockpit state : present - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' - name : Start and enable service ansible.builtin.service : name : cockpit.socket - name : Wait 15 seconds port 9090 ansible.builtin.wait_for : port : 9090 delay : 15 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : - name : Install cockpit package ansible.builtin.package : name : cockpit state : present - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' - name : Start and enable service ansible.builtin.service : name : cockpit state : started enabled : true - name : Wait 15 seconds port 9090 ansible.builtin.wait_for : port : 9090 delay : 15 Comparing the two results, the only notable difference between the two approaches are Lines 27-29 from the SINGLE TASK generative AI approach. Both the SINGLE TASK and MULTI-TASK suggestions for that particular task satisfy the request made by the user. However, whether the single task or multi-task approach resulted in a better code suggestion is up to the judgement of the programmer. Nearly 90% of the remaining code was identical between the two approaches and was achieved in far fewer lines of code (and less typing) using the multi-task approach. The variability of generative AI suggestions is a fascinating topic and one that we will dive more deeply into with the module ahead. Before moving on to other product features, experiment by creating a new Ansible Playbook in your workspace using the code template below. Suggestions will be given on how to perform the same automation task using single and multi-task generation approaches. Save the YAML file as create_ec2_single_multi.yml Copy the following code block to your clipboard using the + icon in the top-right corner of the panel and paste into the newly created YAML file HOW TO CREATE NEW YAML PLAYBOOKS Note: You need to copy and paste the contents of the Playbook into a New File... within the same Lightspeed project directory that was used for the previous lab modules in order for the VS Code extension to engage. To create a new YAML Playbook within a VS Code environment: a. Copy the contents of the Playbook to clipboard using the button in the top-right corner of the lab guide code block. b. Return to your VS Code environment. In the top-left corner of the interface, with your Ansible Lightspeed folder selected, click the New File... button. c. Name the file to a description of your choosing, ending with .yml as the filetype. Set it to CustomPlaybook.yml , for example. Save it to one of the directories in the ansible-wca-demo-kit folder. d. Paste the clipboard contents into the YAML file and follow along with the suggestions below. COPY AND PASTE CODE WITHIN THE VM Information \"copied\" to your local machine's clipboard cannot be \"pasted\" directly into the virtual machine (VM) environment or VS Code. If you wish to copy and paste instructions directly from the lab documentation, it is recommended that you open the GitHub instructions inside the VM's web browser (Firefox). This will allow you to copy instructions to the VM's clipboard and paste instructions inside the VS Code editor. ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible ~/Documents/ansible-wca-demo-kit/create_ec2_single_multi.yml 1 2 3 4 --- - name : Provision an EC2 instance hosts : all tasks : First, configure the Playbook for single task generation by adding the following code snippet into Line 5 (remembering to properly indent with Tab or Space characters): - name : create vpc named demo Your workspace Playbook should look identical to the TEMPLATE tab below. Place your cursor at the end of the newly-created Line 5 and hit Enter to execute single task code generation. Compare your results to the SOLUTION tab. Record your results to a notepad so that you can compare the results later. TEMPLATE SOLUTION 1 2 3 4 5 --- - name : Provision an EC2 instance hosts : all tasks : - name : create vpc named demo 1 2 3 4 5 6 7 8 9 10 11 12 --- - name : Provision an EC2 instance hosts : all tasks : - name : create vpc named demo amazon.aws.ec2_vpc_net : name : demo cidr_block : 10.0.0.80/16 tags : Name : demo tenancy : default register : vpc Now it's time to re-write the Playbook for multi-task code generation. The beauty of natural language statements is that your approach can be as terse or verbose as you want. The more verbose and descriptive, the more prescriptive you can be in terms of influencing the AI-generated code recommendations from WCA. The topic of \"prompt tuning\" will be explored in much greater detail in the Task Description Tuning and Model Customization module. But for now: Replace all of the code inside create_ec2_single_multi.yml with the TEMPLATE code block (below) Place your cursor at the end of Line 5 (remember not to remove the # character) and hit Enter , then accept the recommendation with Tab Compare your results to the SOLUTION tab and to the result from Step 13 TEMPLATE SOLUTION 1 2 3 4 5 --- - name : Provision an EC2 instance hosts : all tasks : # create vpc named demo & create security group for demo vpc and allow ssh and http & create internet gateway named demogateway for demo vpc & create subnet named demosubnet in demo vpc & create route table for subnet demosubnet and gateway demogateway & create t2.small ec2 instance in subnet demosubnet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 --- - name : Provision an EC2 instance hosts : all tasks : # create vpc named demo & create security group for demo vpc and allow ssh and http & create internet gateway named demogateway for demo vpc & create subnet named demosubnet in demo vpc & create route table for subnet demosubnet and gateway demogateway & create t2.small ec2 instance in subnet demosubnet - name : Create vpc named demo amazon.aws.ec2_vpc_net : name : demo cidr_block : 10.0.0.80/16 tags : Name : demo tenancy : default register : vpc - name : Create security group for demo vpc and allow ssh and http amazon.aws.ec2_security_group : name : demo description : demo security group vpc_id : \"{ vpc.vpc.id }\" rules : - proto : tcp from_port : 22 to_port : 22 cidr_ip : 0.0.0.0/0 - proto : tcp from_port : 80 to_port : 80 cidr_ip : 0.0.0.0/0 register : sg - name : Create internet gateway named demogateway for demo vpc amazon.aws.ec2_vpc_igw : vpc_id : \"{ vpc.vpc.id }\" tags : Name : demogateway register : igw - name : Create subnet named demosubnet in demo vpc amazon.aws.ec2_vpc_subnet : cidr : 10.0.0.80/24 vpc_id : \"{ vpc.vpc.id }\" tags : Name : demosubnet register : subnet - name : Create route table for subnet demosubnet and gateway demogateway amazon.aws.ec2_vpc_route_table : vpc_id : \"{ vpc.vpc.id }\" tags : Name : demosubnet subnets : - \"{ subnet.subnet.id }\" routes : - dest : 0.0.0.0/0 gateway_id : \"{ igw.gateway_id }\" register : route_table - name : Create t2.small ec2 instance in subnet demosubnet amazon.aws.ec2_instance : key_name : \"{ _key_name_ }\" instance_type : t2.small image : \"{ _image_ }\" wait : true vpc_subnet_id : \"{ subnet.subnet.id }\" security_group : demo register : ec2 TIMEOUT WARNING It may take several moments for WCA to process and return code recommendations for a multi-task description as complex as this one. If you receive a time-out warning, try executing the code generation step by pressing Enter a second time. Next steps The following module will examine in detail WCA's post-processing and content source attribution capabilities.","title":"Generating Code"},{"location":"generating/#generating-code-with-ibm-watsonx-code-assistant-for-red-hat-ansible-lightspeed","text":"","title":"Generating Code with IBM watsonx Code Assistant for Red Hat Ansible Lightspeed"},{"location":"generating/#_1","text":"An Ansible Task is a statement in Ansible's automation script (the YAML-based Playbooks you will be working with) that declares a single action to be executed. This might be installing a package, copying a file, or shutting down a service on a remote machine. Each Task represents an idempotent operation (an action that can be repeated multiple times and deliver the same result every time) that aligns the remote managed node to the specified state. Idempotent operations also ensure consistency across multiple executions, guaranteeing the same steps are taken on each execution of the task. At the time of publication, IBM watsonx Code Assistant for Red Hat Ansible Lightspeed ( WCA ) will only generate code for Ansible Tasks , including both single task and multi-task automation. Once you have learned the fundamentals of generating Task code blocks, you'll be ready to shape and tailor the AI-generated code recommendations using WCA's model tuning capabilities.","title":""},{"location":"generating/#_2","text":"","title":""},{"location":"generating/#generating-code-for-single-task-ansible-operations","text":"The process of creating AI-generated code recommendations is as simple as modifying the natural language (plain English) Task descriptions of an action that is to be executed, which always start with - name: and are followed by some description of the task to be performed. Ansible Tasks are often preceded with some # comments or documentation. After the natural language description of the automation Task has been set by the user, WCA handles the rest. WCA is also capable of generating multiple Ansible Tasks from more complex natural language descriptions\u2014 what is referred to as multi-task code generation \u2014which you will experiment with later in this module. However, to get started, let's begin with the basics of generating code for single task use cases. Begin by opening the install_cockpit_single-task.yml Playbook from the list of assets in the Explorer browser. Click the Explorer tab from the left-hand interface [A] Drill down into the Install and configure Cockpit using Ansible subdirectory [B] Double-click the install_cockpit_single-task.yml Playbook A replica of the Playbook code is also included below in the documentation The red highlighting within the editor reminds users that the tasks: section contains no valid -name: task definitions. This is part of WCA's code validation process which runs automatically and alerts users to syntax errors in their code. You can safely ignore these warnings for now, as you will be un-commenting and generating valid -name: task definitions in the following steps. ~/Documents/ansible-wca-demo-kit/install and configure Cockpit using Ansible/install_cockpit_single-task.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 --- - name : Install and configure Cockpit hosts : rhel become : true # module_defaults: # ansible.builtin.service: # enabled: true # state: started tasks : # TASK 1 # # 1a. Uncomment task description below and generate a task suggestion. # # Note - The suggestion included Ansible best practices by using Fully Qualified Collection name. # - name: Install cockpit package # TASK 2 # # 2a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used \"ansible.builtin.template\" module based on the \".j2\" file extension. # # Note - The suggestion set the file permissions (\"0644\"), owner, and group based on Ansible best practices. # - name: Copy cockpit.conf.j2 to /etc/cockpit # TASK 3 # # 3a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used the generic \"Start and enable service\" prompt # # and full Playbook context to infer the recommendation should start the \"cockpit\" service. # # 3b. Uncomment the \"module_defaults\" section at the top of the Playbook. # # 3c. Clear current task suggestion and request updated suggestion. # # Note - Ansible Lightspeed used the full Playbook context and evaluated the \"module_defaults\" # # when generating a suggestion. # # The updated suggestion no longer includes \"enabled:\" and \"state:\" arguments. # - name: Start and enable service # TASK 4 # # 4a. Uncomment task description below and generate an Ansible Playbook task suggestion. # # 4b. Save the Playbook. # - name: Wait 15 seconds port 9090 The install_cockpit_single-task.yml Playbook code above warrants some explanation before we move on with making AI-generated modifications to it: Line 2 essentially marks the beginning of the Playbook instructions, the purpose of which is to automate the process of installing and configuring Cockpit for Red Hat Ansible. Lines 3-4 define variables that will remain static throughout the remainder of the Playbook. These variables will be referenced by the AI-generated code suggestions at a later stage. This is a key capability of the offering and one which you will explore in much finer details later on in this module. Lines 6-9 are variables which have been commented out and therefore are invisible to the execution of the Ansible script and not examined by WCA for context when generating code recommendations. You will experiment with how removing the # comment blocks impacts the recommendations of task block code. \"Uncommenting\" these lines of code will make them viable for execution and these lines will afterwards be considered as valid Playbook \"context\" for AI code generation. Locate TASK 1 on Line 15 of the YAML file, which handles installation of Cockpit for Ansible. Cockpit is an interactive server administration interface that provides a graphical overview of statistics and configurations for a system or systems within a network. # - name: Install cockpit package Pay attention to the indentation and characters used on Line 15 , which in sequence from left to right are as follows: begins with a Tab indentation a # character to \"comment out\" the line contents a whitespace Space character - name: which signifies the start of a Task definition and finally the natural language description of the Task INDENTATION LEVELS AND WHITESPACE Similarly to Python, Ansible and YAML-based Playbooks are very sensitive to whitespacing and indentation. Indentations (such as the Tab in this example) denote different hierarchies and code nesting levels within the YAML structure. You may use Space instead of Tab if you prefer, but be sure to use indentations consistently : choose to use either Tab or Space for indenting lines of code, and do not interchange between the two. To generate code for TASK 1 using WCA, first uncomment the line of code (remove # characters from the start of a line). Highlight the line(s) of code you wish to uncomment and then press Cmd + ? for macOS or Ctrl + ? for Windows You can repeat those keystrokes with the line(s) selected to toggle between commenting or uncommenting lines of code Tip: commented out lines of code in VS Code will appear as green text Afterwards, Line 15 should look like the following \u2014 beginning with a single Tab : - name : Install cockpit package Now you are ready to begin generating code. Place your cursor on Line 15 and hit Enter Wait for WCA to engage and generate the suggested (in grey, italicized text ) code block for executing the task This temporary code suggestion is entirely generated by AI As a user, you have the option to either: Accept the code recommendation as-given by pressing Tab Modify the recommended code by highlighting and replacing the italicized text ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible Hit Tab to accept the suggested code and then compare with the SOLUTION tab below. TEMPLATE SOLUTION # TASK 1 - name : Install cockpit package # TASK 1 - name : Install cockpit package ansible.builtin.package : name : cockpit state : present As part of the plain-text description of the Task, WCA was asked to include the cockpit Role, part of the Red Hat Enterprise Linux System Roles Certified Content Collection. The AI-generated code suggestion invoked a Fully Qualified Collection Name ( FQCN ) - ansible.builtin.package Making use of FQCNs where possible is a recommended best practice and is a prime example of the many ways in which the offering infuses post-processing capabilities within the AI-generated code produced by WCA. Additional examples of infusing best-practices into AI-generated code recommendations can be found in TASK 2 ( Line 21 of the unmodified template or Line 25 after Step 5 ): Uncomment - name: Copy cockpit.conf.j2 to /etc/cockpit Hit Enter to generate the task code recommendation and accept the AI-suggested code (without modifications) by pressing Tab Compare your results with the SOLUTION tab below TEMPLATE SOLUTION # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' The AI-generated code recommendation will copy cockpit.conf to the target host. Take note of the fact that the recommendation included the mode: argument and set the Linux file permissions to 0644 , neither of which were things explicitly requested in the Task -name description, but are both additions which adhere to best practices around defining Ansible automaton tasks. Setting a file permission to 0644 specifies read and write permissions for User and Group levels within the Linux OS, and provides only read permissions to all others. These additional recommendations stem from a robust example of setting file permissions for the ansible.builtin.copy module, a recommended best practice from the Ansible Galaxy and Red Hat communities that WCA included in the AI-generated code as well.","title":"Generating code for single task Ansible operations"},{"location":"generating/#_3","text":"","title":""},{"location":"generating/#generating-code-for-multi-task-ansible-operations","text":"Up to this point, we've kept a narrow aperture on AI-generated recommendations for single tasks \u2014 examining and experimenting with generating Ansible code task by task, one at a time. However, a powerful WCA feature is the ability to combine multiple task descriptions into a single natural language prompt; in turn, WCA is able to parse that instruction, decompose the instruction into discrete Ansible Task parts, and return a complete code recommendation for achieving the author's intended goal. Synatically, multiple tasks are combined into a single natural language expression through the use of ampersand ( % ) characters. Simply write out all the automation task descriptions on a single line, separating each description with a % character. The line must also begin with a # character for reasons that will be explained shortly. To illustrate, let's look at a multi-task Ansible Playbook: install_cockpit_multi-task.yml The contents of this Playbook should look familiar to you already: it is essentially the same Playbook examined in Steps 1-6 ( install_cockpit_single-task.yml ), re-written in an equivalent multi-task expression Each of the Task descriptions from the previous Playbook have been consolidated into a single description on Line 12 , separated by % characters ~/Documents/ansible-wca-demo-kit/install and configure Cockpit using Ansible/install_cockpit_multi-task.yml 1 2 3 4 5 6 7 8 9 10 11 12 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : # Install cockpit package & Copy cockpit.conf.j2 to /etc/cockpit & Start and enable service & Wait 15 seconds port 9090 There are two crucial distinctions between single task and multi-task code generation: formatting and execution. Formatting : Notice that Line 12 does not begin with -name: , as was the case with single task descriptions Execution : In order to generate AI code recommendations for multi-task descriptions, Line 12 must stay commented out (the # needs to remain at the start of the line) What is the rationale behind this? When WCA's generative AI capabilities parse Line 12 , its output will include multiple -name: tasks, each containing potentially multiple lines of instructions, based on how many % -delineated task descriptions are included on the line. Therefore, the way in which the code generation step is executed on Line 12 is a consequence of the formatting decision. Execution of a code generation step on a commented-out ( # ) line containing % delineators is recognized by WCA as a unique case that will be acted upon as a multi-task statement. Place your cursor at the end of Line 12 , and without removing the # character, press Enter to execute the code generation step. Be aware that generating code for multi-task descriptions will take longer compared to a single task. Compare the MULTI-TASK solution tab with the SINGLE TASK solution (copied over from Step 6 ). How did the multi-task code generation fare compared to the single task approach? MULTI-TASK SINGLE TASK 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : - name : Install cockpit package ansible.builtin.package : name : cockpit state : present - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' - name : Start and enable service ansible.builtin.service : name : cockpit.socket - name : Wait 15 seconds port 9090 ansible.builtin.wait_for : port : 9090 delay : 15 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : - name : Install cockpit package ansible.builtin.package : name : cockpit state : present - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' - name : Start and enable service ansible.builtin.service : name : cockpit state : started enabled : true - name : Wait 15 seconds port 9090 ansible.builtin.wait_for : port : 9090 delay : 15 Comparing the two results, the only notable difference between the two approaches are Lines 27-29 from the SINGLE TASK generative AI approach. Both the SINGLE TASK and MULTI-TASK suggestions for that particular task satisfy the request made by the user. However, whether the single task or multi-task approach resulted in a better code suggestion is up to the judgement of the programmer. Nearly 90% of the remaining code was identical between the two approaches and was achieved in far fewer lines of code (and less typing) using the multi-task approach. The variability of generative AI suggestions is a fascinating topic and one that we will dive more deeply into with the module ahead. Before moving on to other product features, experiment by creating a new Ansible Playbook in your workspace using the code template below. Suggestions will be given on how to perform the same automation task using single and multi-task generation approaches. Save the YAML file as create_ec2_single_multi.yml Copy the following code block to your clipboard using the + icon in the top-right corner of the panel and paste into the newly created YAML file HOW TO CREATE NEW YAML PLAYBOOKS Note: You need to copy and paste the contents of the Playbook into a New File... within the same Lightspeed project directory that was used for the previous lab modules in order for the VS Code extension to engage. To create a new YAML Playbook within a VS Code environment: a. Copy the contents of the Playbook to clipboard using the button in the top-right corner of the lab guide code block. b. Return to your VS Code environment. In the top-left corner of the interface, with your Ansible Lightspeed folder selected, click the New File... button. c. Name the file to a description of your choosing, ending with .yml as the filetype. Set it to CustomPlaybook.yml , for example. Save it to one of the directories in the ansible-wca-demo-kit folder. d. Paste the clipboard contents into the YAML file and follow along with the suggestions below. COPY AND PASTE CODE WITHIN THE VM Information \"copied\" to your local machine's clipboard cannot be \"pasted\" directly into the virtual machine (VM) environment or VS Code. If you wish to copy and paste instructions directly from the lab documentation, it is recommended that you open the GitHub instructions inside the VM's web browser (Firefox). This will allow you to copy instructions to the VM's clipboard and paste instructions inside the VS Code editor. ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible ~/Documents/ansible-wca-demo-kit/create_ec2_single_multi.yml 1 2 3 4 --- - name : Provision an EC2 instance hosts : all tasks : First, configure the Playbook for single task generation by adding the following code snippet into Line 5 (remembering to properly indent with Tab or Space characters): - name : create vpc named demo Your workspace Playbook should look identical to the TEMPLATE tab below. Place your cursor at the end of the newly-created Line 5 and hit Enter to execute single task code generation. Compare your results to the SOLUTION tab. Record your results to a notepad so that you can compare the results later. TEMPLATE SOLUTION 1 2 3 4 5 --- - name : Provision an EC2 instance hosts : all tasks : - name : create vpc named demo 1 2 3 4 5 6 7 8 9 10 11 12 --- - name : Provision an EC2 instance hosts : all tasks : - name : create vpc named demo amazon.aws.ec2_vpc_net : name : demo cidr_block : 10.0.0.80/16 tags : Name : demo tenancy : default register : vpc Now it's time to re-write the Playbook for multi-task code generation. The beauty of natural language statements is that your approach can be as terse or verbose as you want. The more verbose and descriptive, the more prescriptive you can be in terms of influencing the AI-generated code recommendations from WCA. The topic of \"prompt tuning\" will be explored in much greater detail in the Task Description Tuning and Model Customization module. But for now: Replace all of the code inside create_ec2_single_multi.yml with the TEMPLATE code block (below) Place your cursor at the end of Line 5 (remember not to remove the # character) and hit Enter , then accept the recommendation with Tab Compare your results to the SOLUTION tab and to the result from Step 13 TEMPLATE SOLUTION 1 2 3 4 5 --- - name : Provision an EC2 instance hosts : all tasks : # create vpc named demo & create security group for demo vpc and allow ssh and http & create internet gateway named demogateway for demo vpc & create subnet named demosubnet in demo vpc & create route table for subnet demosubnet and gateway demogateway & create t2.small ec2 instance in subnet demosubnet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 --- - name : Provision an EC2 instance hosts : all tasks : # create vpc named demo & create security group for demo vpc and allow ssh and http & create internet gateway named demogateway for demo vpc & create subnet named demosubnet in demo vpc & create route table for subnet demosubnet and gateway demogateway & create t2.small ec2 instance in subnet demosubnet - name : Create vpc named demo amazon.aws.ec2_vpc_net : name : demo cidr_block : 10.0.0.80/16 tags : Name : demo tenancy : default register : vpc - name : Create security group for demo vpc and allow ssh and http amazon.aws.ec2_security_group : name : demo description : demo security group vpc_id : \"{ vpc.vpc.id }\" rules : - proto : tcp from_port : 22 to_port : 22 cidr_ip : 0.0.0.0/0 - proto : tcp from_port : 80 to_port : 80 cidr_ip : 0.0.0.0/0 register : sg - name : Create internet gateway named demogateway for demo vpc amazon.aws.ec2_vpc_igw : vpc_id : \"{ vpc.vpc.id }\" tags : Name : demogateway register : igw - name : Create subnet named demosubnet in demo vpc amazon.aws.ec2_vpc_subnet : cidr : 10.0.0.80/24 vpc_id : \"{ vpc.vpc.id }\" tags : Name : demosubnet register : subnet - name : Create route table for subnet demosubnet and gateway demogateway amazon.aws.ec2_vpc_route_table : vpc_id : \"{ vpc.vpc.id }\" tags : Name : demosubnet subnets : - \"{ subnet.subnet.id }\" routes : - dest : 0.0.0.0/0 gateway_id : \"{ igw.gateway_id }\" register : route_table - name : Create t2.small ec2 instance in subnet demosubnet amazon.aws.ec2_instance : key_name : \"{ _key_name_ }\" instance_type : t2.small image : \"{ _image_ }\" wait : true vpc_subnet_id : \"{ subnet.subnet.id }\" security_group : demo register : ec2 TIMEOUT WARNING It may take several moments for WCA to process and return code recommendations for a multi-task description as complex as this one. If you receive a time-out warning, try executing the code generation step by pressing Enter a second time.","title":"Generating code for multi-task Ansible operations"},{"location":"generating/#_4","text":"","title":""},{"location":"generating/#next-steps","text":"The following module will examine in detail WCA's post-processing and content source attribution capabilities.","title":"Next steps"},{"location":"setup/","text":"Installation of Visual Studio Code and Extensions Before getting started with IBM watsonx Code Assistant for Red Hat Ansible Lightspeed ( WCA ), you will first setup Visual Studio Code (commonly referred to as VS Code ) on a local machine. This will provide an integrated development environment for experimenting with WCA's generative AI capabilities. Download the latest Stable Build [A] release of VS Code availabe for your machine's operating system using the link below. Download : https://code.visualstudio.com Follow along with the installer wizard steps and continue with the hands-on lab instructions once VS Code is running on your local machine. FULLSCREEN IMAGES Click on any of the screenshots within this documentation to enlarge the image. Launch the VS Code application and take note of the sidebar along the left-side. Click the Extensions icon [A] to open the marketplace of services and open source technologies that can be integrated with VS Code If you have used VS Code previously, extensions that have already been integrated with the environment will be listed along the left side At the top of the Extensions panel is a search bar: Type Ansible into the search bar [A] and then hit Enter Click the blue Install button [B] for the official Ansible extension for VS Code, published by Red Hat (blue checkmark) INSTALLATION PROMPTS You may receive two different prompts during the installation process: Do you trust the authors of the files in this workspace? : select Trust Workspace & Install Do you want to allow untrusted files in this window? : select Open Installation of the Ansible extension for VS Code should only take a moment \u2014 an Extension:Ansible welcome panel will open when it is finished Once the Ansible extension has been integrated with VS Code, close any Welcome tabs that open and look for Ansible under the Installed services in the Extensions panel. Click the Manage (\"cogwheel\") icon located just to the right of the Ansible tile From the drop-down options, click Extension Settings [A] Settings for the Ansible extension will be displayed within a new panel. Ensure that User [A] is selected at the top of the panel \u2014 do not edit Workspace Using the search bar [B] at the top of the panel, add the text Lightspeed to filter the available options Check the option for Ansible > Lightspeed [C] Check the option for Ansible > Lightspeed: Suggestions [D] Check the option for Ansible > Lightspeed: Disable Content Suggestion Header [E] Changes to Settings are automatically saved and applied \u2013 click the X button in the top-left corner of the panel's tab Accessing your Red Hat credentials and authenticating with WCA Red Hat credentials will already have been emailed to you prior to starting this hands-on material, as part of the registration process. The invitation email will have a header similar to Red Hat Login Email Verification , addressed from a no-reply@redhat.com account. Locate this email in your inbox and follow along with the steps below to authenticate the VS Code extension with the IBM watsonx Code Assistant for Red Hat Ansible Lightspeed (WCA) environment that has been pre-provisioned for this training. Click the URL [A] located within the body of the invitation email to finalize your account registration with the WCA environment. An Email Confirmation page will load within your web browser Record the value of Red Hat login to a notepad for reference later Create a new Password and record this to a notepad for reference later When ready, click Save [B] to finalize registration REGISTRATION IS REQUIRED If you already have a personal account with Red Hat, you must still register for a new account using the invitation URL provided Do not attempt to use a personal Red Hat account in the later steps of the Setup & Troubleshooting guide, as that account will not have access to the WCA services needed to perform the training Red Hat accounts created for this training will be de-authorized and deleted after the hands-on training period has ended Return to the VS Code editor and click the Ansible plugin [A] (denoted by the A logo) on the left-hand side of the interface. Two panels will open along the left side of the interface Within the Ansible Lightspeed Login panel, click the blue Connect button [B] The extension Ansible wants to sign in using Ansible Lightspeed : click Allow [C] Do you want Code to open the external website? : click Open [D] A web browser will load with the header Log in to Ansible Lightspeed with IBM watsonx Code Assistant \u2014 this is where you will supply your registration details recorded in Step 6 in order to authenticate the VS Code plugin with WCA. Click the Log in with Red Hat button [A] If you had previously logged in to Red Hat with your browser, you might not be asked again for those credentials If you are asked to provide a Username and Password , supply the values recorded in Step 6 of this module After logging in with Red Hat, the web browser will display the prompt to Authorize Ansible Lightspeed for VS Code . Click Authorize [A] Do you want to allow this website to open Visual Studio Code? : click Allow [B] Allow Ansible extension to open this URI? : click Open [C] At this stage, the Ansible extension for VS Code is now authenticated and connected to IBM watsonx Code Assistant . Verify [A] that the environment is logged in as your unique Username and that the User Type: Licensed A notification pop-up will also appear in the bottom-right corner of the VS Code interface confirming the successful login CLICK TO EXPAND \u2014 FAILURE TO LOGIN OR TIMED OUT If the authentication procedure in Steps 7-9 takes too long, activation of the plugin will be \"timed out\" and the VS Code environment will display an error message [B] in the bottom-right corner Click the Connect [C] button as shown and repeat Steps 7-9 as before; the login process should run smoother (and faster) on the second attempt Preparing the Ansible Playbook materials To begin experimenting with WCA's generative AI capabilities, you will first need access to some Ansible Playbooks to generate Tasks with. Playbook templates have already been prepared ahead of time for this training so that you can get straight to work. Click the Explorer button at the top of the left-hand VS Code interface. Depending on your VS Code environment, the Explorer tab will look one of two ways. Click to expand whichever one of the two options best describes your situation and follow the instructions. I AM NEW TO VS CODE If you are working within a new installation of VS Code, the Explorer tab [A] will display NO FOLDER OPENED and give options to either Open Folder or Clone Repository . You must specify the public GitHub repository from which to \"clone\" the Ansible Playbook templates into the local (VS Code) environment. A \"clone\" request in GitHub is essentially a request to replicate code from the cloud-hosted repository into the local environment. Click the Clone Repository button [B] , which will open an executable console [C] at the top of VS Code You must specify the public GitHub repository from which to \"clone\" the Ansible Playbook templates into the local (VS Code) environment Enter following GitHub repository address into the console and hit Enter to confirm: https://github.com/chetan-hireholi/ansible-wca-demo-kit If prompted Would you like to open the cloned repository? : click Open [D] If prompted Do you trust the authors of the files in this folder? : click Yes, I trust the authors [E] I HAVE USED VS CODE BEFORE If you have worked with VS Code before and have added projects or folders to the environment previously, those folders (and their contents) will be displayed within the Explorer tab. However, you still need to clone (replicate) the Ansible Playbook templates from GitHub to a folder on your local machine. A \"clone\" request in GitHub is essentially a request to replicate code from the cloud-hosted repository into the local environment. To perform a clone request with VS Code, perform the following action (depending on your OS): Windows : Press Ctrl + Shift + P to open an executable console at the top of VS Code macOS : Press Cmd + Shift + P to open an executable console at the top of VS Code Enter following command into the console and hit Enter to confirm: git:clone Next, specify the public repository from which to clone the Ansible Playbook templates. Enter following GitHub repository address into the console and hit Enter to confirm: https://github.com/chetan-hireholi/ansible-wca-demo-kit Regardless of whether you are new to VS Code or have used VS Code previously, the remainder of the steps in the Setup & Troubleshooting module are the same. Confirm that the working directory [A] is now set to ansible-wca-demo-kit and that it contains files similar to those listed in the screenshot below. As a final step, verify that the VM has access to the latest demo code by performing the following git fetch and git pull commands: From the top of the VM interface, drill down into View and then Command Palette [A] Into the pop-up console [B] , type git fetch , hit Enter , and wait patiently for the operation to finish Open the console once again, type git pull , and then hit Enter At this stage, the hands-on environment has been fully configured Troubleshooting and support If you require assistance or run into issues with the hands-on lab, help is available. Environment issues: The lab environment is managed by IBM Technology Zone. Opening a support case ticket is recommended for issues related to the hands-on environment (provisioning, running, and so on.) Documentation issues: If there is an error in the lab documentation, or if you require additional support in completing the material, open a thread on the #wca-ansible-techzone-support Slack channel. Product questions: For questions related to IBM watsonx Code Assistant capabilities, sales opportunities, roadmap, and other such matters, open a thread on the #watsonx-code-assistant Slack channel. As you settle in to the environment and begin your training, you may encounter unexpected warnings or errors. Many of these can be safely ignored or can be easily rectified. This section will serve as a running list of frequently asked questions and troubleshooting techniques. Click on any of the following topics for additional details. FAILED TO CONNECT TO THE SERVER This warning will occur when the Ansible plugin for VS Code needs to be re-authenticated with WCA. It can occur after an extended period of inactivity or a system restart. For example, if your lab environment is running inside a VM, pausing or restarting the VM may produce this error. To re-authenticate: Sign out from the VS Code application by clicking the User icon [A] in the bottom-left corner of the interface, hover over your username, and then click Sign Out [B] If you are running this environment inside a virtual machine (VM) , closing and restarting the VM will not resolve the issue \u2014 you must sign out from the VS Code application, not the VM Once logged out, follow from Step 7 of the Setup & Troubleshooting to re-authenticate with WCA ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible ANSIBLE-LINT IS NOT AVAILABLE ansible-lint checks playbooks for practices and behavior that could potentially be improved and can fix some of the most common ones for you. It will constantly check your Ansible syntax as you type and provide recommendations for how to improve it. You can safely ignore this error if it occurs during the lab exercises. RED ANSIBLE ICON ALONG BOTTOM-RIGHT INTERFACE The Ansible extension for VS Code will check your local machine to determine if Red Hat Ansible has been installed locally. If you have not set up Ansible (the standalone version) on your local machine previously, this tile will display as red. You can safely ignore this error if it occurs during the lab exercises. CANNOT SET PROPERTIES OF UNDEFINED (SETTING 'currentModelValue') Make sure that the Model ID Override field is set to empty in your Ansible for VS Code extension settings. To verify this: Click the Extensions tab [A] along the left-hand interface Click the Manage icon [B] on the right side of the Ansible extension tile, then drill down into Extension Settings [C] Add the text Model to the search filter [D] at the top of the Extension Settings panel Clear the input field [E] of any model IDs and leave it blank Close the Extension Settings panel by clicking X and return to the Ansible Playbook SPAWN C:\\Windows\\system32\\cmd.exe ENOENT This warning is not related to Ansible or WCA. You can safely ignore this error if it occurs during the lab exercises. PYTHON DRIVERS ARE MISSING The WCA extension for VS Code requires that Python drivers are included within the workspace. These are usually configured within VS Code by default, but can be easily set if necessary. Look for a Python tile adjacent to the Ansible tile along the bottom-right corner of the VS Code interface. If it is not set, click the tile and select the Python 3.11.5 64-bit drivers. Click the gold-colored Select python environment button at the bottom-right of the interface From the console at the top of the VS Code environment, select the recommended Python 3.11.5 64-bit option and hit Enter to confirm COPY AND PASTE INSTRUCTIONS INTO A VIRTUAL MACHINE If you are running the lab environment inside a virtual machine (VM), it might not be possible to \"paste\" lab instructions from your local machine's clipboard directly into the VM. If you wish to copy and paste instructions directly from the lab documentation, it is recommended that you open the GitHub instructions inside the VM's web browser (Firefox). This will allow you to copy instructions to the VM's clipboard and paste instructions inside the VS Code editor. Next steps The following section will cover the fundamentals of AI-recommended code generation for Ansible Playbooks using IBM watsonx Code Assistant .","title":"Setup and Troubleshooting"},{"location":"setup/#installation-of-visual-studio-code-and-extensions","text":"","title":"Installation of Visual Studio Code and Extensions"},{"location":"setup/#_1","text":"Before getting started with IBM watsonx Code Assistant for Red Hat Ansible Lightspeed ( WCA ), you will first setup Visual Studio Code (commonly referred to as VS Code ) on a local machine. This will provide an integrated development environment for experimenting with WCA's generative AI capabilities. Download the latest Stable Build [A] release of VS Code availabe for your machine's operating system using the link below. Download : https://code.visualstudio.com Follow along with the installer wizard steps and continue with the hands-on lab instructions once VS Code is running on your local machine. FULLSCREEN IMAGES Click on any of the screenshots within this documentation to enlarge the image. Launch the VS Code application and take note of the sidebar along the left-side. Click the Extensions icon [A] to open the marketplace of services and open source technologies that can be integrated with VS Code If you have used VS Code previously, extensions that have already been integrated with the environment will be listed along the left side At the top of the Extensions panel is a search bar: Type Ansible into the search bar [A] and then hit Enter Click the blue Install button [B] for the official Ansible extension for VS Code, published by Red Hat (blue checkmark) INSTALLATION PROMPTS You may receive two different prompts during the installation process: Do you trust the authors of the files in this workspace? : select Trust Workspace & Install Do you want to allow untrusted files in this window? : select Open Installation of the Ansible extension for VS Code should only take a moment \u2014 an Extension:Ansible welcome panel will open when it is finished Once the Ansible extension has been integrated with VS Code, close any Welcome tabs that open and look for Ansible under the Installed services in the Extensions panel. Click the Manage (\"cogwheel\") icon located just to the right of the Ansible tile From the drop-down options, click Extension Settings [A] Settings for the Ansible extension will be displayed within a new panel. Ensure that User [A] is selected at the top of the panel \u2014 do not edit Workspace Using the search bar [B] at the top of the panel, add the text Lightspeed to filter the available options Check the option for Ansible > Lightspeed [C] Check the option for Ansible > Lightspeed: Suggestions [D] Check the option for Ansible > Lightspeed: Disable Content Suggestion Header [E] Changes to Settings are automatically saved and applied \u2013 click the X button in the top-left corner of the panel's tab","title":""},{"location":"setup/#_2","text":"","title":""},{"location":"setup/#accessing-your-red-hat-credentials-and-authenticating-with-wca","text":"Red Hat credentials will already have been emailed to you prior to starting this hands-on material, as part of the registration process. The invitation email will have a header similar to Red Hat Login Email Verification , addressed from a no-reply@redhat.com account. Locate this email in your inbox and follow along with the steps below to authenticate the VS Code extension with the IBM watsonx Code Assistant for Red Hat Ansible Lightspeed (WCA) environment that has been pre-provisioned for this training. Click the URL [A] located within the body of the invitation email to finalize your account registration with the WCA environment. An Email Confirmation page will load within your web browser Record the value of Red Hat login to a notepad for reference later Create a new Password and record this to a notepad for reference later When ready, click Save [B] to finalize registration REGISTRATION IS REQUIRED If you already have a personal account with Red Hat, you must still register for a new account using the invitation URL provided Do not attempt to use a personal Red Hat account in the later steps of the Setup & Troubleshooting guide, as that account will not have access to the WCA services needed to perform the training Red Hat accounts created for this training will be de-authorized and deleted after the hands-on training period has ended Return to the VS Code editor and click the Ansible plugin [A] (denoted by the A logo) on the left-hand side of the interface. Two panels will open along the left side of the interface Within the Ansible Lightspeed Login panel, click the blue Connect button [B] The extension Ansible wants to sign in using Ansible Lightspeed : click Allow [C] Do you want Code to open the external website? : click Open [D] A web browser will load with the header Log in to Ansible Lightspeed with IBM watsonx Code Assistant \u2014 this is where you will supply your registration details recorded in Step 6 in order to authenticate the VS Code plugin with WCA. Click the Log in with Red Hat button [A] If you had previously logged in to Red Hat with your browser, you might not be asked again for those credentials If you are asked to provide a Username and Password , supply the values recorded in Step 6 of this module After logging in with Red Hat, the web browser will display the prompt to Authorize Ansible Lightspeed for VS Code . Click Authorize [A] Do you want to allow this website to open Visual Studio Code? : click Allow [B] Allow Ansible extension to open this URI? : click Open [C] At this stage, the Ansible extension for VS Code is now authenticated and connected to IBM watsonx Code Assistant . Verify [A] that the environment is logged in as your unique Username and that the User Type: Licensed A notification pop-up will also appear in the bottom-right corner of the VS Code interface confirming the successful login CLICK TO EXPAND \u2014 FAILURE TO LOGIN OR TIMED OUT If the authentication procedure in Steps 7-9 takes too long, activation of the plugin will be \"timed out\" and the VS Code environment will display an error message [B] in the bottom-right corner Click the Connect [C] button as shown and repeat Steps 7-9 as before; the login process should run smoother (and faster) on the second attempt","title":"Accessing your Red Hat credentials and authenticating with WCA"},{"location":"setup/#_3","text":"","title":""},{"location":"setup/#preparing-the-ansible-playbook-materials","text":"To begin experimenting with WCA's generative AI capabilities, you will first need access to some Ansible Playbooks to generate Tasks with. Playbook templates have already been prepared ahead of time for this training so that you can get straight to work. Click the Explorer button at the top of the left-hand VS Code interface. Depending on your VS Code environment, the Explorer tab will look one of two ways. Click to expand whichever one of the two options best describes your situation and follow the instructions. I AM NEW TO VS CODE If you are working within a new installation of VS Code, the Explorer tab [A] will display NO FOLDER OPENED and give options to either Open Folder or Clone Repository . You must specify the public GitHub repository from which to \"clone\" the Ansible Playbook templates into the local (VS Code) environment. A \"clone\" request in GitHub is essentially a request to replicate code from the cloud-hosted repository into the local environment. Click the Clone Repository button [B] , which will open an executable console [C] at the top of VS Code You must specify the public GitHub repository from which to \"clone\" the Ansible Playbook templates into the local (VS Code) environment Enter following GitHub repository address into the console and hit Enter to confirm: https://github.com/chetan-hireholi/ansible-wca-demo-kit If prompted Would you like to open the cloned repository? : click Open [D] If prompted Do you trust the authors of the files in this folder? : click Yes, I trust the authors [E] I HAVE USED VS CODE BEFORE If you have worked with VS Code before and have added projects or folders to the environment previously, those folders (and their contents) will be displayed within the Explorer tab. However, you still need to clone (replicate) the Ansible Playbook templates from GitHub to a folder on your local machine. A \"clone\" request in GitHub is essentially a request to replicate code from the cloud-hosted repository into the local environment. To perform a clone request with VS Code, perform the following action (depending on your OS): Windows : Press Ctrl + Shift + P to open an executable console at the top of VS Code macOS : Press Cmd + Shift + P to open an executable console at the top of VS Code Enter following command into the console and hit Enter to confirm: git:clone Next, specify the public repository from which to clone the Ansible Playbook templates. Enter following GitHub repository address into the console and hit Enter to confirm: https://github.com/chetan-hireholi/ansible-wca-demo-kit Regardless of whether you are new to VS Code or have used VS Code previously, the remainder of the steps in the Setup & Troubleshooting module are the same. Confirm that the working directory [A] is now set to ansible-wca-demo-kit and that it contains files similar to those listed in the screenshot below. As a final step, verify that the VM has access to the latest demo code by performing the following git fetch and git pull commands: From the top of the VM interface, drill down into View and then Command Palette [A] Into the pop-up console [B] , type git fetch , hit Enter , and wait patiently for the operation to finish Open the console once again, type git pull , and then hit Enter At this stage, the hands-on environment has been fully configured","title":"Preparing the Ansible Playbook materials"},{"location":"setup/#_4","text":"","title":""},{"location":"setup/#troubleshooting-and-support","text":"If you require assistance or run into issues with the hands-on lab, help is available. Environment issues: The lab environment is managed by IBM Technology Zone. Opening a support case ticket is recommended for issues related to the hands-on environment (provisioning, running, and so on.) Documentation issues: If there is an error in the lab documentation, or if you require additional support in completing the material, open a thread on the #wca-ansible-techzone-support Slack channel. Product questions: For questions related to IBM watsonx Code Assistant capabilities, sales opportunities, roadmap, and other such matters, open a thread on the #watsonx-code-assistant Slack channel. As you settle in to the environment and begin your training, you may encounter unexpected warnings or errors. Many of these can be safely ignored or can be easily rectified. This section will serve as a running list of frequently asked questions and troubleshooting techniques. Click on any of the following topics for additional details. FAILED TO CONNECT TO THE SERVER This warning will occur when the Ansible plugin for VS Code needs to be re-authenticated with WCA. It can occur after an extended period of inactivity or a system restart. For example, if your lab environment is running inside a VM, pausing or restarting the VM may produce this error. To re-authenticate: Sign out from the VS Code application by clicking the User icon [A] in the bottom-left corner of the interface, hover over your username, and then click Sign Out [B] If you are running this environment inside a virtual machine (VM) , closing and restarting the VM will not resolve the issue \u2014 you must sign out from the VS Code application, not the VM Once logged out, follow from Step 7 of the Setup & Troubleshooting to re-authenticate with WCA ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible ANSIBLE-LINT IS NOT AVAILABLE ansible-lint checks playbooks for practices and behavior that could potentially be improved and can fix some of the most common ones for you. It will constantly check your Ansible syntax as you type and provide recommendations for how to improve it. You can safely ignore this error if it occurs during the lab exercises. RED ANSIBLE ICON ALONG BOTTOM-RIGHT INTERFACE The Ansible extension for VS Code will check your local machine to determine if Red Hat Ansible has been installed locally. If you have not set up Ansible (the standalone version) on your local machine previously, this tile will display as red. You can safely ignore this error if it occurs during the lab exercises. CANNOT SET PROPERTIES OF UNDEFINED (SETTING 'currentModelValue') Make sure that the Model ID Override field is set to empty in your Ansible for VS Code extension settings. To verify this: Click the Extensions tab [A] along the left-hand interface Click the Manage icon [B] on the right side of the Ansible extension tile, then drill down into Extension Settings [C] Add the text Model to the search filter [D] at the top of the Extension Settings panel Clear the input field [E] of any model IDs and leave it blank Close the Extension Settings panel by clicking X and return to the Ansible Playbook SPAWN C:\\Windows\\system32\\cmd.exe ENOENT This warning is not related to Ansible or WCA. You can safely ignore this error if it occurs during the lab exercises. PYTHON DRIVERS ARE MISSING The WCA extension for VS Code requires that Python drivers are included within the workspace. These are usually configured within VS Code by default, but can be easily set if necessary. Look for a Python tile adjacent to the Ansible tile along the bottom-right corner of the VS Code interface. If it is not set, click the tile and select the Python 3.11.5 64-bit drivers. Click the gold-colored Select python environment button at the bottom-right of the interface From the console at the top of the VS Code environment, select the recommended Python 3.11.5 64-bit option and hit Enter to confirm COPY AND PASTE INSTRUCTIONS INTO A VIRTUAL MACHINE If you are running the lab environment inside a virtual machine (VM), it might not be possible to \"paste\" lab instructions from your local machine's clipboard directly into the VM. If you wish to copy and paste instructions directly from the lab documentation, it is recommended that you open the GitHub instructions inside the VM's web browser (Firefox). This will allow you to copy instructions to the VM's clipboard and paste instructions inside the VS Code editor.","title":"Troubleshooting and support"},{"location":"setup/#_5","text":"","title":""},{"location":"setup/#next-steps","text":"The following section will cover the fundamentals of AI-recommended code generation for Ansible Playbooks using IBM watsonx Code Assistant .","title":"Next steps"},{"location":"source-matching-post-processing/","text":"Content source matching and attribution At this point, you should now be well acquianted with Ansible Tasks and Playbooks . Ansible Playbooks are comprised of multiple Tasks \u2014 which you have been using IBM watsonx Code Assistant's ( WCA ) generative AI capabilities to define and expand upon. If a Playbook contains multiple \"tasks\" that together achieve some singular goal or purpose, you may want to group these tasks into a single reusable unit. For example, a string of \"tasks\" might provision infrastructure for separate development, test, and production clusters from a major cloud vendor. Patterns for automating endpoints from these vendors can be codified into Ansible Modules , which are supported by Red Hat and the Ansible community writ large. And finally, collections of Playbooks and Modules can be organized into \"blueprints\" for automation tasks that are frequently used together to achieve some goal; a goal which you might want to make repeatable or shareable with other teams within your business. These blueprints are referred to as Ansible Roles . They provide a structured way to organize tasks, templates, files, and variables, and are available to drop directly into Ansible Playbooks. Roles make it possible to easily manage and set up complex automation tasks, essentially providing a rubric to streamline automation projects. Collectively, these Playbooks, Modules, and Roles form a comprehensive ecosystem of business and community-driven support for patterning automation to work with the broadest range of vendors, technologies, and clouds. Ansible Galaxy is a Red Hat-curated, community-driven repository for Ansible Roles . Via communities such as Galaxy, thousands of Roles are available for Ansible users to leverage within their own Playbooks. Ansible Galaxy is also key to how generative AI code recommendations from WCA are attributed back to original content sources and authors. A powerful capability within WCA is Content Source Matching (often referred to as \"code explainability\"), which attempts to match AI-generated code suggestions to the training data and sources that were utilized in generating the suggested Task code. These code attribution suggestions are created using a k-NN ( K-Nearest Neighbors ) algorithm that examines Ansible Galaxy and training data repositories in search of the nearest related content to the AI-generated code suggestions. To enable Content Source Matching capabilities within WCA, navigate to the main menu bar for VS Code and drill down into View > Open View... [A] The console [A] along the top of the VS Code interface is now activated and awaiting a prompt. Type Lightspeed Training Matches and hit Enter to confirm the selection. After making this configuration change to VS Code, all requests for WCA to generate code recommendations will now open a panel at the bottom of the VS Code interface It is under the Ansible tab that content source matching results will be displayed Other tabs will also displayed for variety of options: Problems , Output , Debug Console , Terminal , and Ports Open the install_pgsql-single-task.yml Ansible Playbook, which is included within the ansible-wca-demo-kit directory. The full location of the Playbook, as well as the contents, are available in the code block below. ~/Documents/ansible-wca-demo-kit/install and configure PostgreSQL and PGAdmin container/install_pgsql-single-task.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 --- - name : Configure Database servers hosts : databases become : true tasks : # TASK 1 # - name: Install postgresql-server # TASK 2 # Ansible Lightspeed used an easy-to-understand natural language prompt and suggested the correct, more complex PostgreSQL CLI command to initiate the database. # Ansible Lightspeed used best practices and kept the task idempotent by including creates: /var/lib/pgsql/data/postgresql.conf in the suggestion. # - name: Run postgresql setup command # TASK 3 # Ansible Lightspeed used natural language prompt and added state: started and enabled: true module arguments based on Start and enable... in the Ansible task description. # - name: Start and enable postgresql service Generate a code recommendation for the task on Line 7 by placing your cursor at the end of the line and hitting Enter . Pay attention to the code attribution details associated with this recommendation, which will be appearing under the Ansible tab at the bottom of the VS Code interface once the code recommendation is finalized. You will need to accept the AI-generated code suggestions (using the Tab key) before the Ansible content source matching tab will provide details about the code's origins. - name : Install postgresql-server ansible.builtin.package : name : postgresql-server state : present The three most likely content sources used in training the WCA model\u2014 which produced the AI-generated code recommendations \u2014are listed within the Ansible tab [A] . Recall from earlier that these code attribution suggestions are created using a k-NN algorithm that searches Ansible Galaxy repositories for the nearest related content to the AI-generated code suggestions. Clicking the arrow icon to the left of each attribution [B] will expand further details about the source. Information about the URL , Path , Data Source , License , Ansible Type , and Score are displayed (where available) under each listing. Red Hat-certified and maintained collections, as well as contributors to open source projects on Ansible Galaxy, are the primary sources for Ansible Lightspeed model training and are the content sources you are most likely to see matched to AI-generated code recommendations. Drilling down into the URL field will redirect your web browser back to the precise collections and sources on Ansible Galaxy from which the code recommendations were derived. Here you can learn much richer details about the status of the project, any associated open source repositories involved (such as GitHub), contributions and activities ongoing with the code base, the author(s) involved, and many more intricacies. Post-processing of Task descriptions and YAML file contents helps generate contextually aware, accurate Ansible content suggestions. Another element of code generation that WCA excels at is understanding context within the Playbook it is executing against. If a variable or attribute is defined earlier within that Playbook, it will be recalled and referenced\u2014 where it makes sense to do so \u2014in the generation of subsequent lines of code. You may have already noticed these post-processing capabilities in your experimentations with WCA-generated code suggestions. However, one way to make this feature quite obvious is to take a previously-generated block of Ansible Task code, update the value assigned to a named variable earlier in the Playbook, and then regenerate the Task code block. In theory, the newly-generated Task block will use the updated variable name (and differ from how the code block was originally generated). Create a New File... YAML Playbook named demo_provision_ec2_instance.yml anywhere within the /ansible-wca-demo-kit/ directory. You may save the Playbook in the root of the folder or any of the subdirectories Be sure to reference the expandable tooltips below for instructions on how to perform these operations and how to configure the Playbook language for use with WCA Copy and paste the following code block into the demo_provision_ec2_instance.yml Playbook and then save the file HOW TO CREATE NEW YAML PLAYBOOKS Note: You need to copy and paste the contents of the Playbook into a New File... within the same Lightspeed project directory that was used for the previous lab modules in order for the VS Code extension to engage. To create a new YAML Playbook within a VS Code environment: a. Copy the contents of the Playbook to clipboard using the button in the top-right corner of the lab guide code block. b. Return to your VS Code environment. In the top-left corner of the interface, with your Ansible Lightspeed folder selected, click the New File... button. c. Name the file to a description of your choosing, ending with .yml as the filetype. Set it to CustomPlaybook.yml , for example. Save it to one of the directories in the ansible-wca-demo-kit folder. d. Paste the clipboard contents into the YAML file and follow along with the suggestions below. COPY AND PASTE CODE WITHIN THE VM Information \"copied\" to your local machine's clipboard cannot be \"pasted\" directly into the virtual machine (VM) environment or VS Code. If you wish to copy and paste instructions directly from the lab documentation, it is recommended that you open the GitHub instructions inside the VM's web browser (Firefox). This will allow you to copy instructions to the VM's clipboard and paste instructions inside the VS Code editor. ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible demo_provision_ec2_instance.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 --- - name : EC2 Cloud Operations hosts : localhost connection : local gather_facts : false module_defaults : group/aws : region : us-east-1 # vars: # ec2_instance: # name: lightspeed-instance-01 # key_name: lightspeed-keypair # image_id: ami-016eb5d644c333ccb # RHEL 9 us-east-1 # tags: # function: lightspeed-demo # security_group: secgroup-lightspeed tasks : # TASK 1 # # 1a. Uncomment task description below and generate a task suggestion. # # Note - Best practices: The suggestion used the Fully Qualified Collection name. # # Note - Context: Ansible Lightspeed used the Playbook name \"EC2 Cloud Operations\" to use the correct \"amazon.aws.ec2_vpc_subnet_info\" module. - name : Gather subnet info tag:Name subnet-lightspeed # TASK 2 # # 2a. Uncomment task description below and generate a task suggestion. # # Note - Context: The suggestion included the previous task's registered variable in the suggestion. # # Note - Accuracy: The suggestion provides the correct key value from the previously task's registered variable. - name : Create vpc_subnet_id var # TASK 3 # # 3a. Uncomment task description \"Provision t3.micro instance\" below and generate a task suggestion. # # Note - Efficiency: The suggestion provides practical variable examples to improve efficiency. - name : Provision t3.micro instance # # 3b. Remove the above task and suggestion. # # Uncomment 2nd task description \"Provision t3.micro instance using ec2_instance var\". # # Generate an updated suggestion. # # Note - Context: The updated suggestion includes the \"ec2_instance variable fields in the suggestion\" - name : Provision t3.micro instance using ec2_instance var TASK 1 ( Line 26 ) and TASK 2 ( Line 33 ) are responsible for gathering information about a network subnet that is to be provisioned and then creating a virtual private cloud (VPC) definition based on those details. Generate suggested code for TASK 1 ( Line 26 ) by un-commenting the line, placing the cursor at the end of the line, hitting Enter , and then confirming with Tab . Afterwards, perform the same steps to generate code for TASK 2 as well. The first round of WCA-generated code for the task on Line 26 produces a code block [A] with a register: subnet_info line, the result of which is to assign this VPC definition to a variable subnet_info . Nothing terribly complicated or surprising about that. The WCA-generated code that follows for the task on Line 38 (previously Line 33 in the raw template) recommends a code block [B] with vpc_subnet_id: \"{ { subnet_info.subnets[0].subnet_id } }\" as the value associated with the VPC's subnet ID. Critically, the variable subnet_info that was generated in the previous Task [A] is also referenced in the second Task. This demonstrates the contextual awareness of WCA in action. Change the name of variable subnet_info to subnet_name on Line 26 . Then delete the code block recommendations under Line 38 and regenerate the task. Notice that the new block [A] of TASK 2 now references the variable subnet_name that was modified just a moment ago in TASK 1 WCA has generated code for TASK 2 that takes into account the modified context and variables from TASK 1 of the Playbook Continue experimenting with WCA's contextual awareness and post-processing capabilities. Try adjusting other variables within the Playbook and study how these modifications impact the generation of later blocks of Task code within the Playbook. Next steps In the next section, you will begin experimentating with customized Ansible Playbooks and testing how changes to Ansible Task natural language descriptions impacts the recommended code produced by WCA.","title":"Content Source Matching and Post-Processing"},{"location":"source-matching-post-processing/#content-source-matching-and-attribution","text":"","title":"Content source matching and attribution"},{"location":"source-matching-post-processing/#_1","text":"At this point, you should now be well acquianted with Ansible Tasks and Playbooks . Ansible Playbooks are comprised of multiple Tasks \u2014 which you have been using IBM watsonx Code Assistant's ( WCA ) generative AI capabilities to define and expand upon. If a Playbook contains multiple \"tasks\" that together achieve some singular goal or purpose, you may want to group these tasks into a single reusable unit. For example, a string of \"tasks\" might provision infrastructure for separate development, test, and production clusters from a major cloud vendor. Patterns for automating endpoints from these vendors can be codified into Ansible Modules , which are supported by Red Hat and the Ansible community writ large. And finally, collections of Playbooks and Modules can be organized into \"blueprints\" for automation tasks that are frequently used together to achieve some goal; a goal which you might want to make repeatable or shareable with other teams within your business. These blueprints are referred to as Ansible Roles . They provide a structured way to organize tasks, templates, files, and variables, and are available to drop directly into Ansible Playbooks. Roles make it possible to easily manage and set up complex automation tasks, essentially providing a rubric to streamline automation projects.","title":""},{"location":"source-matching-post-processing/#_2","text":"","title":""},{"location":"source-matching-post-processing/#collectively-these-playbooks-modules-and-roles-form-a-comprehensive-ecosystem-of-business-and-community-driven-support-for-patterning-automation-to-work-with-the-broadest-range-of-vendors-technologies-and-clouds","text":"","title":"Collectively, these Playbooks, Modules, and Roles form a comprehensive ecosystem of business and community-driven support for patterning automation to work with the broadest range of vendors, technologies, and clouds."},{"location":"source-matching-post-processing/#_3","text":"Ansible Galaxy is a Red Hat-curated, community-driven repository for Ansible Roles . Via communities such as Galaxy, thousands of Roles are available for Ansible users to leverage within their own Playbooks. Ansible Galaxy is also key to how generative AI code recommendations from WCA are attributed back to original content sources and authors. A powerful capability within WCA is Content Source Matching (often referred to as \"code explainability\"), which attempts to match AI-generated code suggestions to the training data and sources that were utilized in generating the suggested Task code. These code attribution suggestions are created using a k-NN ( K-Nearest Neighbors ) algorithm that examines Ansible Galaxy and training data repositories in search of the nearest related content to the AI-generated code suggestions. To enable Content Source Matching capabilities within WCA, navigate to the main menu bar for VS Code and drill down into View > Open View... [A] The console [A] along the top of the VS Code interface is now activated and awaiting a prompt. Type Lightspeed Training Matches and hit Enter to confirm the selection. After making this configuration change to VS Code, all requests for WCA to generate code recommendations will now open a panel at the bottom of the VS Code interface It is under the Ansible tab that content source matching results will be displayed Other tabs will also displayed for variety of options: Problems , Output , Debug Console , Terminal , and Ports Open the install_pgsql-single-task.yml Ansible Playbook, which is included within the ansible-wca-demo-kit directory. The full location of the Playbook, as well as the contents, are available in the code block below. ~/Documents/ansible-wca-demo-kit/install and configure PostgreSQL and PGAdmin container/install_pgsql-single-task.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 --- - name : Configure Database servers hosts : databases become : true tasks : # TASK 1 # - name: Install postgresql-server # TASK 2 # Ansible Lightspeed used an easy-to-understand natural language prompt and suggested the correct, more complex PostgreSQL CLI command to initiate the database. # Ansible Lightspeed used best practices and kept the task idempotent by including creates: /var/lib/pgsql/data/postgresql.conf in the suggestion. # - name: Run postgresql setup command # TASK 3 # Ansible Lightspeed used natural language prompt and added state: started and enabled: true module arguments based on Start and enable... in the Ansible task description. # - name: Start and enable postgresql service Generate a code recommendation for the task on Line 7 by placing your cursor at the end of the line and hitting Enter . Pay attention to the code attribution details associated with this recommendation, which will be appearing under the Ansible tab at the bottom of the VS Code interface once the code recommendation is finalized. You will need to accept the AI-generated code suggestions (using the Tab key) before the Ansible content source matching tab will provide details about the code's origins. - name : Install postgresql-server ansible.builtin.package : name : postgresql-server state : present The three most likely content sources used in training the WCA model\u2014 which produced the AI-generated code recommendations \u2014are listed within the Ansible tab [A] . Recall from earlier that these code attribution suggestions are created using a k-NN algorithm that searches Ansible Galaxy repositories for the nearest related content to the AI-generated code suggestions. Clicking the arrow icon to the left of each attribution [B] will expand further details about the source. Information about the URL , Path , Data Source , License , Ansible Type , and Score are displayed (where available) under each listing. Red Hat-certified and maintained collections, as well as contributors to open source projects on Ansible Galaxy, are the primary sources for Ansible Lightspeed model training and are the content sources you are most likely to see matched to AI-generated code recommendations. Drilling down into the URL field will redirect your web browser back to the precise collections and sources on Ansible Galaxy from which the code recommendations were derived. Here you can learn much richer details about the status of the project, any associated open source repositories involved (such as GitHub), contributions and activities ongoing with the code base, the author(s) involved, and many more intricacies.","title":""},{"location":"source-matching-post-processing/#_4","text":"","title":""},{"location":"source-matching-post-processing/#post-processing-of-task-descriptions-and-yaml-file-contents-helps-generate-contextually-aware-accurate-ansible-content-suggestions","text":"","title":"Post-processing of Task descriptions and YAML file contents helps generate contextually aware, accurate Ansible content suggestions."},{"location":"source-matching-post-processing/#_5","text":"Another element of code generation that WCA excels at is understanding context within the Playbook it is executing against. If a variable or attribute is defined earlier within that Playbook, it will be recalled and referenced\u2014 where it makes sense to do so \u2014in the generation of subsequent lines of code. You may have already noticed these post-processing capabilities in your experimentations with WCA-generated code suggestions. However, one way to make this feature quite obvious is to take a previously-generated block of Ansible Task code, update the value assigned to a named variable earlier in the Playbook, and then regenerate the Task code block. In theory, the newly-generated Task block will use the updated variable name (and differ from how the code block was originally generated). Create a New File... YAML Playbook named demo_provision_ec2_instance.yml anywhere within the /ansible-wca-demo-kit/ directory. You may save the Playbook in the root of the folder or any of the subdirectories Be sure to reference the expandable tooltips below for instructions on how to perform these operations and how to configure the Playbook language for use with WCA Copy and paste the following code block into the demo_provision_ec2_instance.yml Playbook and then save the file HOW TO CREATE NEW YAML PLAYBOOKS Note: You need to copy and paste the contents of the Playbook into a New File... within the same Lightspeed project directory that was used for the previous lab modules in order for the VS Code extension to engage. To create a new YAML Playbook within a VS Code environment: a. Copy the contents of the Playbook to clipboard using the button in the top-right corner of the lab guide code block. b. Return to your VS Code environment. In the top-left corner of the interface, with your Ansible Lightspeed folder selected, click the New File... button. c. Name the file to a description of your choosing, ending with .yml as the filetype. Set it to CustomPlaybook.yml , for example. Save it to one of the directories in the ansible-wca-demo-kit folder. d. Paste the clipboard contents into the YAML file and follow along with the suggestions below. COPY AND PASTE CODE WITHIN THE VM Information \"copied\" to your local machine's clipboard cannot be \"pasted\" directly into the virtual machine (VM) environment or VS Code. If you wish to copy and paste instructions directly from the lab documentation, it is recommended that you open the GitHub instructions inside the VM's web browser (Firefox). This will allow you to copy instructions to the VM's clipboard and paste instructions inside the VS Code editor. ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible demo_provision_ec2_instance.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 --- - name : EC2 Cloud Operations hosts : localhost connection : local gather_facts : false module_defaults : group/aws : region : us-east-1 # vars: # ec2_instance: # name: lightspeed-instance-01 # key_name: lightspeed-keypair # image_id: ami-016eb5d644c333ccb # RHEL 9 us-east-1 # tags: # function: lightspeed-demo # security_group: secgroup-lightspeed tasks : # TASK 1 # # 1a. Uncomment task description below and generate a task suggestion. # # Note - Best practices: The suggestion used the Fully Qualified Collection name. # # Note - Context: Ansible Lightspeed used the Playbook name \"EC2 Cloud Operations\" to use the correct \"amazon.aws.ec2_vpc_subnet_info\" module. - name : Gather subnet info tag:Name subnet-lightspeed # TASK 2 # # 2a. Uncomment task description below and generate a task suggestion. # # Note - Context: The suggestion included the previous task's registered variable in the suggestion. # # Note - Accuracy: The suggestion provides the correct key value from the previously task's registered variable. - name : Create vpc_subnet_id var # TASK 3 # # 3a. Uncomment task description \"Provision t3.micro instance\" below and generate a task suggestion. # # Note - Efficiency: The suggestion provides practical variable examples to improve efficiency. - name : Provision t3.micro instance # # 3b. Remove the above task and suggestion. # # Uncomment 2nd task description \"Provision t3.micro instance using ec2_instance var\". # # Generate an updated suggestion. # # Note - Context: The updated suggestion includes the \"ec2_instance variable fields in the suggestion\" - name : Provision t3.micro instance using ec2_instance var TASK 1 ( Line 26 ) and TASK 2 ( Line 33 ) are responsible for gathering information about a network subnet that is to be provisioned and then creating a virtual private cloud (VPC) definition based on those details. Generate suggested code for TASK 1 ( Line 26 ) by un-commenting the line, placing the cursor at the end of the line, hitting Enter , and then confirming with Tab . Afterwards, perform the same steps to generate code for TASK 2 as well. The first round of WCA-generated code for the task on Line 26 produces a code block [A] with a register: subnet_info line, the result of which is to assign this VPC definition to a variable subnet_info . Nothing terribly complicated or surprising about that. The WCA-generated code that follows for the task on Line 38 (previously Line 33 in the raw template) recommends a code block [B] with vpc_subnet_id: \"{ { subnet_info.subnets[0].subnet_id } }\" as the value associated with the VPC's subnet ID. Critically, the variable subnet_info that was generated in the previous Task [A] is also referenced in the second Task. This demonstrates the contextual awareness of WCA in action. Change the name of variable subnet_info to subnet_name on Line 26 . Then delete the code block recommendations under Line 38 and regenerate the task. Notice that the new block [A] of TASK 2 now references the variable subnet_name that was modified just a moment ago in TASK 1 WCA has generated code for TASK 2 that takes into account the modified context and variables from TASK 1 of the Playbook Continue experimenting with WCA's contextual awareness and post-processing capabilities. Try adjusting other variables within the Playbook and study how these modifications impact the generation of later blocks of Task code within the Playbook.","title":""},{"location":"source-matching-post-processing/#_6","text":"","title":""},{"location":"source-matching-post-processing/#next-steps","text":"In the next section, you will begin experimentating with customized Ansible Playbooks and testing how changes to Ansible Task natural language descriptions impacts the recommended code produced by WCA.","title":"Next steps"}]}